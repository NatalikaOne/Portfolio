{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Техническое задание 3\n",
        "\n",
        "**Дообучение автокорректора JamSpell на синтетически сгенерированных OCR-ошибках.**\n",
        "\n",
        "Дообучить любой автокорректор на литературных текстах для улучшения качества коррекции ошибок при распознавании текста. В дообучении использовать тексты от 100 тыс. предложений. В ходе работы ТЗ дополнено: увеличить данные для обучения до 200 тыс. предложений.\n"
      ],
      "metadata": {
        "id": "M1p8uIIQ9oMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## План работы\n",
        "\n",
        "1. **Анализ основных ошибок в распознавании текста после работы модели Tesseract.**\n",
        "- Загрузить тексты\n",
        "- Вывести ошибки, после распознавания моделью текста. Проанализировать: какие ошибки пропускает модель.\n",
        "\n",
        "2. **Подготовка текста для дообучения.**\n",
        "* Выбор автокорректора для дообучения.\n",
        "* Загрузка текста для генерации ошибок размером более 100 тыс.предложений.\n",
        "* Сгенерировать OCR-ошибки\n",
        "* Создание датасета\n",
        "\n",
        "3. **Дообучение автокорректора JamSpell**\n",
        "* Дообучение автокорректора JamSpell.\n",
        "* Тестирование дообученной модели на тестовых данных\n",
        "* Анализ метрик WER и CER после дообучения.\n",
        "\n",
        "4. **Анализ и выводы о качестве работы дообученного автокорректора.**"
      ],
      "metadata": {
        "id": "WUqO-Gnz-N1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Загрузка библиотек**"
      ],
      "metadata": {
        "id": "362YTGk2zAdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snsJIO-32KH4",
        "outputId": "1979ccaf-dcee-484f-ba93-bea15ecbc219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract pillow jiwer # установка библиотеки для вычисления метрик"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuDyOfopPO8P",
        "outputId": "b484c79d-ed3b-49af-d006-c596c0603cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, pytesseract, jiwer\n",
            "Successfully installed jiwer-3.1.0 pytesseract-0.3.13 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ],
      "metadata": {
        "id": "M8I5nmAbaiqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "iL70RKXq1Qf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import difflib\n",
        "import re\n",
        "import os\n",
        "import string\n",
        "import jiwer # библиотека для вычисления метрик"
      ],
      "metadata": {
        "id": "c44yJ3XUbzfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка seed для воспроизводимости\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "hLiTVcen0TXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install striprtf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc0-H6ZEpHtH",
        "outputId": "e2bd31ba-1b6e-4693-89d4-45f8a515a83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.29-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading striprtf-0.0.29-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from striprtf.striprtf import rtf_to_text # Для открытия файлов rtf"
      ],
      "metadata": {
        "id": "VBkmjrDLra5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Библиотеки для JamSpell**"
      ],
      "metadata": {
        "id": "Mznu7cAc9dds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!sudo apt-get install swig3.0 # для JamSpell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYrdYBM57Cxu",
        "outputId": "d76d993f-7b54-4e4a-9619-54f951e95afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'Reading package lists... 0%',\n",
              " '',\n",
              " 'Reading package lists... 0%',\n",
              " '',\n",
              " 'Reading package lists... 0%',\n",
              " '',\n",
              " 'Reading package lists... 3%',\n",
              " '',\n",
              " 'Reading package lists... 3%',\n",
              " '',\n",
              " 'Reading package lists... 3%',\n",
              " '',\n",
              " 'Reading package lists... 3%',\n",
              " '',\n",
              " 'Reading package lists... 37%',\n",
              " '',\n",
              " 'Reading package lists... 37%',\n",
              " '',\n",
              " 'Reading package lists... 37%',\n",
              " '',\n",
              " 'Reading package lists... 37%',\n",
              " '',\n",
              " 'Reading package lists... 37%',\n",
              " '',\n",
              " 'Reading package lists... 44%',\n",
              " '',\n",
              " 'Reading package lists... 44%',\n",
              " '',\n",
              " 'Reading package lists... 54%',\n",
              " '',\n",
              " 'Reading package lists... 54%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 58%',\n",
              " '',\n",
              " 'Reading package lists... 65%',\n",
              " '',\n",
              " 'Reading package lists... 65%',\n",
              " '',\n",
              " 'Reading package lists... 74%',\n",
              " '',\n",
              " 'Reading package lists... 74%',\n",
              " '',\n",
              " 'Reading package lists... 77%',\n",
              " '',\n",
              " 'Reading package lists... 77%',\n",
              " '',\n",
              " 'Reading package lists... 77%',\n",
              " '',\n",
              " 'Reading package lists... 77%',\n",
              " '',\n",
              " 'Reading package lists... 78%',\n",
              " '',\n",
              " 'Reading package lists... 78%',\n",
              " '',\n",
              " 'Reading package lists... 82%',\n",
              " '',\n",
              " 'Reading package lists... 82%',\n",
              " '',\n",
              " 'Reading package lists... 87%',\n",
              " '',\n",
              " 'Reading package lists... 95%',\n",
              " '',\n",
              " 'Reading package lists... 95%',\n",
              " '',\n",
              " 'Reading package lists... 98%',\n",
              " '',\n",
              " 'Reading package lists... 98%',\n",
              " '',\n",
              " 'Reading package lists... 98%',\n",
              " '',\n",
              " 'Reading package lists... 98%',\n",
              " '',\n",
              " 'Reading package lists... 99%',\n",
              " '',\n",
              " 'Reading package lists... 99%',\n",
              " '',\n",
              " 'Reading package lists... 99%',\n",
              " '',\n",
              " 'Reading package lists... 99%',\n",
              " '',\n",
              " 'Reading package lists... Done',\n",
              " '',\n",
              " 'Building dependency tree... 0%',\n",
              " '',\n",
              " 'Building dependency tree... 0%',\n",
              " '',\n",
              " 'Building dependency tree... 50%',\n",
              " '',\n",
              " 'Building dependency tree... 50%',\n",
              " '',\n",
              " 'Building dependency tree... Done',\n",
              " '',\n",
              " 'Reading state information... 0% ',\n",
              " '',\n",
              " 'Reading state information... 0%',\n",
              " '',\n",
              " 'Reading state information... Done',\n",
              " 'Suggested packages:',\n",
              " '  swig3.0-examples swig3.0-doc',\n",
              " 'The following NEW packages will be installed:',\n",
              " '  swig3.0',\n",
              " '0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.',\n",
              " 'Need to get 1,109 kB of archives.',\n",
              " 'After this operation, 5,555 kB of additional disk space will be used.',\n",
              " '',\n",
              " '0% [Working]',\n",
              " '            ',\n",
              " 'Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig3.0 amd64 3.0.12-2.2ubuntu1 [1,109 kB]',\n",
              " '',\n",
              " '1% [1 swig3.0 14.2 kB/1,109 kB 1%]',\n",
              " '                                  ',\n",
              " '100% [Working]',\n",
              " '              ',\n",
              " 'Fetched 1,109 kB in 0s (2,254 kB/s)',\n",
              " 'debconf: unable to initialize frontend: Dialog',\n",
              " 'debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)',\n",
              " 'debconf: falling back to frontend: Readline',\n",
              " 'debconf: unable to initialize frontend: Readline',\n",
              " 'debconf: (This frontend requires a controlling tty.)',\n",
              " 'debconf: falling back to frontend: Teletype',\n",
              " 'dpkg-preconfigure: unable to re-open stdin: ',\n",
              " 'Selecting previously unselected package swig3.0.',\n",
              " '(Reading database ... ',\n",
              " '(Reading database ... 5%',\n",
              " '(Reading database ... 10%',\n",
              " '(Reading database ... 15%',\n",
              " '(Reading database ... 20%',\n",
              " '(Reading database ... 25%',\n",
              " '(Reading database ... 30%',\n",
              " '(Reading database ... 35%',\n",
              " '(Reading database ... 40%',\n",
              " '(Reading database ... 45%',\n",
              " '(Reading database ... 50%',\n",
              " '(Reading database ... 55%',\n",
              " '(Reading database ... 60%',\n",
              " '(Reading database ... 65%',\n",
              " '(Reading database ... 70%',\n",
              " '(Reading database ... 75%',\n",
              " '(Reading database ... 80%',\n",
              " '(Reading database ... 85%',\n",
              " '(Reading database ... 90%',\n",
              " '(Reading database ... 95%',\n",
              " '(Reading database ... 100%',\n",
              " '(Reading database ... 126213 files and directories currently installed.)',\n",
              " 'Preparing to unpack .../swig3.0_3.0.12-2.2ubuntu1_amd64.deb ...',\n",
              " 'Unpacking swig3.0 (3.0.12-2.2ubuntu1) ...',\n",
              " 'Setting up swig3.0 (3.0.12-2.2ubuntu1) ...',\n",
              " 'Processing triggers for man-db (2.10.2-1) ...']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install jamspell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAX-20Iw7C73",
        "outputId": "66d73d94-d25a-486e-f501-0cac8ed2b9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jamspell\n",
            "  Downloading jamspell-0.0.12.tar.gz (174 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/174.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m174.1/174.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: jamspell\n",
            "  Building wheel for jamspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jamspell: filename=jamspell-0.0.12-cp311-cp311-linux_x86_64.whl size=1785475 sha256=3556fa9626f55bf08f2b9ec77d5bde56d4ee18486df745480bd3b42582e9e2b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/f7/b1/1314c3a8f44a8e2bbe9f90b2ae05c404068f797b7681e1163b\n",
            "Successfully built jamspell\n",
            "Installing collected packages: jamspell\n",
            "Successfully installed jamspell-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O ru.bin https://github.com/bakwc/JamSpell-models/raw/master/ru.tar.gz\n",
        "!tar -xzf ru.bin || echo \"Ошибка: файл ru.bin не распакован\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GARh4Opn7C-m",
        "outputId": "a13f4b09-4929-4402-ea3e-9d27c92d194c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-07 09:37:31--  https://github.com/bakwc/JamSpell-models/raw/master/ru.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bakwc/JamSpell-models/master/ru.tar.gz [following]\n",
            "--2025-04-07 09:37:31--  https://raw.githubusercontent.com/bakwc/JamSpell-models/master/ru.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39663667 (38M) [application/octet-stream]\n",
            "Saving to: ‘ru.bin’\n",
            "\n",
            "ru.bin              100%[===================>]  37.83M   207MB/s    in 0.2s    \n",
            "\n",
            "2025-04-07 09:37:32 (207 MB/s) - ‘ru.bin’ saved [39663667/39663667]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jamspell"
      ],
      "metadata": {
        "id": "nnRqKlOHYbFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Анализ ошибок после распознавания текста**"
      ],
      "metadata": {
        "id": "T9IgNJaRNncm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо проанализировать основные ошибки в распознавании текста после работы модели Tesseract. Для этого загрузим распознанные моделью в предыдущих работах  тексты, эталонные тексты и используем метрики WER и CER, а так же выведем список ошибок, которые пропустила модель."
      ],
      "metadata": {
        "id": "eZJUuw3Uz6MB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка текстов"
      ],
      "metadata": {
        "id": "NDVvM_fBT-6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # подключение гугл диска с файлами\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiVffVClUqtB",
        "outputId": "0a3de51e-7ee9-40bc-c72c-99be865a8433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Литературный текст**"
      ],
      "metadata": {
        "id": "FCCrxdowZJ0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rec_lit_text = '/content/drive/My Drive/Files_for_project/rec_lit_text.txt'\n",
        "rec_lit_text = open(rec_lit_text, 'r', encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "b9KGTTcWYwV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "etalon_lit_text = '/content/drive/My Drive/Files_for_project/etalon_lit_text.txt'\n",
        "etalon_lit_text = open(etalon_lit_text, 'r', encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "3lgZ4zgCFJ6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rec_lit_text[0:500])\n",
        "print(etalon_lit_text[0:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIz6ZkWEZU16",
        "outputId": "adb485cc-b822-4315-e311-32ee8cf69cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "по-видимому, с вестибюля. В заплесневелых углах белесо мерцали кости прикованных скелетов, где-то мерно капала вода, в нишах между колоннами в неестественных позах торчали статуи в ржавых латах, справа от входа у стены громоздились обломки древних идолов, наверху этой кучи торчали гипсовые ноги в сапогах. С почерневших портретов под потолком строго взирали маститые старцы, в их лицах усматривались знакомые черты Федора Симеоновича, товарища Жиана Жиакомо и других мастеров. Весь этот архаический \n",
            "﻿по-видимому, с вестибюля. В заплесневелых углах белесо мерцали кости прикованных скелетов, где-то мерно капала вода, в нишах между колоннами в неестественных позах торчали статуи в ржавых латах, справа от входа у стены громоздились обломки древних идолов, наверху этой кучи торчали гипсовые ноги в сапогах. С почерневших портретов под потолком строго взирали маститые старцы, в их лицах усматривались знакомые черты Федора Симеоновича, товарища Жиана Жиакомо и других мастеров. Весь этот архаический\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Учебный текст**"
      ],
      "metadata": {
        "id": "aJHVLSwMZO9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rec_educ_text = '/content/drive/My Drive/Files_for_project/rec_educ_text.txt'\n",
        "rec_educ_text = open(rec_educ_text, 'r', encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "Uvz47yUdYy_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "etalon_educ_text = '/content/drive/My Drive/Files_for_project/etalon_educ_text.txt'\n",
        "etalon_educ_text = open(etalon_educ_text, 'r', encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "Kuhtrz71YzCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rec_educ_text[0:500])\n",
        "print(etalon_educ_text[0:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFJ2GVLBYzEu",
        "outputId": "1442e9ae-9c4c-4c97-a635-9eb43f82f3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Субъектом правопонимания всегда выступает конкретный человек, например: а) гражданин, обладающий минимальным правовым кругозором, столкнувшийся с проблемами права вообще; 6) юрист-профессионал, имеющий достаточный запас знаний о праве, способный применять и толковать правовые нормы; в) ученый, человек с абстрактным мышлением, занимающийся изучением права, обладающий суммой исторических и современных знаний, способный к интерпретации не только норм, но и принципов права, владеющий определенной ме\n",
            "﻿Субъектом правопонимания всегда выступает конкретный человек, например: а) гражданин, обладающий минимальным правовым кругозором, столкнувшийся с проблемами права вообще; б) юрист-профессионал, имеющий достаточный запас знаний о праве, способный применять и толковать правовые нормы; в) ученый, человек с абстрактным мышлением, занимающийся изучением права, обладающий суммой исторических и современных знаний, способный к интерпретации не только норм, но и принципов права, владеющий определенной м\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Анализ ошибок при распознавании текста моделью"
      ],
      "metadata": {
        "id": "wMICWKKAU0EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Удаляет знаки пунктуации из текста, кроме точек в сокращениях.\"\"\"\n",
        "    return re.sub(r\"[.,!?;:\\\"'()\\—]\", \"\", text)"
      ],
      "metadata": {
        "id": "SUqnU4EqAkVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_errors(ocr_text, reference_text):\n",
        "    \"\"\"Находит ошибки OCR: замененные, пропущенные и лишние слова.\"\"\"\n",
        "\n",
        "    # Очистка от запятых, тире и других знаков\n",
        "    ocr_text = clean_text(ocr_text)\n",
        "    reference_text = clean_text(reference_text)\n",
        "\n",
        "    ocr_words = ocr_text.split()\n",
        "    reference_words = reference_text.split()\n",
        "\n",
        "    matcher = difflib.SequenceMatcher(None, reference_words, ocr_words)\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    for opcode, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "        if opcode == \"replace\":  # Слова заменены\n",
        "            ref_part = \" \".join(reference_words[i1:i2])\n",
        "            ocr_part = \" \".join(ocr_words[j1:j2])\n",
        "            errors.append((ocr_part, ref_part, \"замена\"))\n",
        "\n",
        "        elif opcode == \"delete\":  # OCR пропустил слово\n",
        "            ref_part = \" \".join(reference_words[i1:i2])\n",
        "            errors.append((\"[пропущено]\", ref_part, \"пропуск\"))\n",
        "\n",
        "        elif opcode == \"insert\":  # OCR добавил лишнее слово\n",
        "            ocr_part = \" \".join(ocr_words[j1:j2])\n",
        "            errors.append((ocr_part, \"[не должно быть]\", \"лишнее\"))\n",
        "\n",
        "    return errors"
      ],
      "metadata": {
        "id": "r4KHG2QEVYwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_lit_text = find_errors(rec_lit_text, etalon_lit_text)\n",
        "for ocr_word, ref_word, error_type in errors_lit_text:\n",
        "    print(f\"Ошибка ({error_type}): '{ocr_word}' → Должно быть: '{ref_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZMeeKpJVYzf",
        "outputId": "151393c6-dfd6-4bde-b955-d68cf448ba90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка (замена): 'по-видимому' → Должно быть: '﻿по-видимому'\n",
            "Ошибка (замена): 'заинвентаризовано' → Должно быть: 'заинвентаризировано'\n",
            "Ошибка (замена): 'паиболее' → Должно быть: 'наиболее'\n",
            "Ошибка (замена): 'нище' → Должно быть: 'нише'\n",
            "Ошибка (замена): 'ктото' → Должно быть: 'кто-то'\n",
            "Ошибка (замена): 'спаружи' → Должно быть: 'снаружи'\n",
            "Ошибка (замена): 'десять пятнадцать' → Должно быть: 'десять-пятнадцать'\n",
            "Ошибка (замена): 'оптнмизм' → Должно быть: 'оптимизм'\n",
            "Ошибка (замена): 'экстракфты' → Должно быть: 'экстракты'\n",
            "Ошибка (замена): 'единой' → Должно быть: 'одной'\n",
            "Ошибка (замена): 'злободроби тель' → Должно быть: 'злободробитель'\n",
            "Ошибка (замена): 'собою' → Должно быть: 'собой'\n",
            "Ошибка (замена): 'вареную' → Должно быть: 'вареную…'\n",
            "Ошибка (замена): 'вниварии' → Должно быть: 'виварии'\n",
            "Ошибка (замена): '‘сипло' → Должно быть: 'сипло'\n",
            "Ошибка (замена): 'СТОЙЛ' → Должно быть: 'стойл'\n",
            "Ошибка (замена): 'ли' → Должно быть: 'ли…'\n",
            "Ошибка (замена): 'в глубь' → Должно быть: 'вглубь'\n",
            "Ошибка (замена): 'года' → Должно быть: 'года…'\n",
            "Ошибка (замена): 'братцыблизнецы' → Должно быть: 'братцы-близнецы'\n",
            "Ошибка (замена): 'девяноста' → Должно быть: 'девяносто'\n",
            "Ошибка (замена): '‘за' → Должно быть: 'за'\n",
            "Ошибка (замена): 'притихЛи' → Должно быть: 'притихли'\n",
            "Ошибка (замена): 'платком-' → Должно быть: 'платком'\n",
            "Ошибка (замена): 'все' → Должно быть: 'все…'\n",
            "Ошибка (замена): 'развсшаны' → Должно быть: 'развешаны'\n",
            "Ошибка (замена): 'Чингис-хана' → Должно быть: 'Чингисхана'\n",
            "Ошибка (замена): '3 Горыныч' → Должно быть: 'ЗГорыныч'\n",
            "Ошибка (замена): 'Кощея' → Должно быть: 'кощея'\n",
            "Ошибка (замена): 'отбыл' → Должно быть: 'отбыл…'\n",
            "Ошибка (замена): '1' → Должно быть: 'к'\n",
            "Ошибка (замена): 'защишать' → Должно быть: 'защищать'\n",
            "Ошибка (замена): 'уточнении' → Должно быть: 'уточнение'\n",
            "Ошибка (замена): 'мегапарсек' → Должно быть: 'мегапарсеков'\n",
            "Ошибка (замена): 'точностн' → Должно быть: 'точности'\n",
            "Ошибка (замена): 'я’' → Должно быть: 'я'\n",
            "Ошибка (замена): 'Онн' → Должно быть: 'Они'\n",
            "Ошибка (замена): 'прошелся' → Должно быть: 'прошел'\n",
            "Ошибка (замена): 'Преображенского' → Должно быть: 'преображенского'\n",
            "Ошибка (пропуск): '[пропущено]' → Должно быть: 'в'\n",
            "Ошибка (замена): '934' → Должно быть: '94'\n",
            "Ошибка (замена): 'рейтарскимн' → Должно быть: 'рейтарскими'\n",
            "Ошибка (замена): 'Велнкому' → Должно быть: 'Великому'\n",
            "Ошибка (замена): 'рассвирепел' → Должно быть: 'рассвирипел'\n",
            "Ошибка (замена): 'протяженин' → Должно быть: 'протяжении'\n",
            "Ошибка (замена): 'Первой' → Должно быть: 'первой'\n",
            "Ошибка (пропуск): '[пропущено]' → Должно быть: 'и'\n",
            "Ошибка (замена): '$5' → Должно быть: '95'\n",
            "Ошибка (замена): 'дальше»' → Должно быть: 'дальше…»'\n",
            "Ошибка (замена): 'валявшуюзся' → Должно быть: 'валявшуюся'\n",
            "Ошибка (замена): 'Г]о' → Должно быть: 'По'\n",
            "Ошибка (замена): 'стеллажей' → Должно быть: 'Стеллажей'\n",
            "Ошибка (замена): 'пиджинннглиш' → Должно быть: 'пиджин-инглиш'\n",
            "Ошибка (замена): 'Книги Судеб' → Должно быть: 'книги судеб'\n",
            "Ошибка (замена): 'Судеб' → Должно быть: 'судеб'\n",
            "Ошибка (замена): '73 619 024 51|-ти' → Должно быть: '73619024511'\n",
            "Ошибка (замена): 'пнтекантропом' → Должно быть: 'питекантропом'\n",
            "Ошибка (замена): '955543' → Должно быть: '965543'\n",
            "Ошибка (замена): 'числил‘я Франсиско-Каэтано-Августин-Лусия-и-Мануэль-и-Хосефа-иМигель-Лука-Карлос-Педро Тринидад' → Должно быть: 'числился Франсиско-Каэтано Августин-Лусия-и-Мануэль-и-Хосефа-и-Мигель-Лука-Карлос-Педро-Тринидад'\n",
            "Ошибка (замена): 'не' → Должно быть: 'н э'\n",
            "Ошибка (замена): 'Педро-Карлос-Лука 56 Мигель-и-Хосефа-и-Мануэль-и-ЛТусия-Августин-Каэтано-Франсиско' → Должно быть: 'Педро Карлос-Лука96 Мигель-и-Хосефа-и-Мануэль-и-Лусия-Августин-Каэтано-Франсиско'\n",
            "Ошибка (замена): 'гварии»' → Должно быть: 'гвардии»'\n",
            "Ошибка (замена): '| один}' → Должно быть: '1 один'\n",
            "Ошибка (замена): 'он' → Должно быть: 'но'\n",
            "Ошибка (замена): 'Предсказаний и Пророчеств' → Должно быть: 'предсказаний и пророчеств'\n",
            "Ошибка (замена): 'ито-нибудь' → Должно быть: 'что-нибудь'\n",
            "Ошибка (замена): 'удивлепными' → Должно быть: 'удивленными'\n",
            "Ошибка (замена): 'вечномолодого' → Должно быть: 'вечно молодого'\n",
            "Ошибка (замена): 'ноблескивающий' → Должно быть: 'поблескивающий'\n",
            "Ошибка (замена): 'расчетамн' → Должно быть: 'расчетами'\n",
            "Ошибка (замена): 'н' → Должно быть: 'и'\n",
            "Ошибка (замена): 'Х\\ита Любивший Во' → Должно быть: 'Хунта любивший во'\n",
            "Ошибка (замена): 'полключать' → Должно быть: 'подключать'\n",
            "Ошибка (замена): '‚место' → Должно быть: 'вместо'\n",
            "Ошибка (замена): 'Чтобы' → Должно быть: 'чтобы'\n",
            "Ошибка (замена): 'шестидесятеричную' → Должно быть: 'шестидесятиричную'\n",
            "Ошибка (замена): 'принцип' → Должно быть: 'принципы'\n",
            "Ошибка (замена): 'пею в чет-печет' → Должно быть: 'ней в чет-нечет'\n",
            "Ошибка (замена): 'се' → Должно быть: 'ее'\n",
            "Ошибка (замена): 'Вселил' → Должно быть: 'вселил'\n",
            "Ошибка (замена): '«неконгруентной' → Должно быть: '«неконгруэнтной'\n",
            "Ошибка (замена): 'инкубпреобразования»' → Должно быть: 'инкуб-преобразования» -'\n",
            "Ошибка (замена): 'Ойры-Ойры' → Должно быть: 'Ойра-Ойры'\n",
            "Ошибка (замена): 'отправился‘на' → Должно быть: 'отправился на'\n",
            "Ошибка (замена): 'административно-хозяйственного' → Должно быть: 'административно хозяйственного'\n",
            "Ошибка (замена): 'Вселенной' → Должно быть: 'вселенной'\n",
            "Ошибка (замена): 'ассимптотического' → Должно быть: 'асимптотического'\n",
            "Ошибка (замена): 'настрльных' → Должно быть: 'настольных'\n",
            "Ошибка (замена): 'Компрене ву 1 Понимаете' → Должно быть: 'Компрэне ву1 1Понимаете'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors_educ_text = find_errors(rec_educ_text, etalon_educ_text)\n",
        "for ocr_word, ref_word, error_type in errors_educ_text:\n",
        "    print(f\"Ошибка ({error_type}): '{ocr_word}' → Должно быть: '{ref_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcwtdD1VVY2D",
        "outputId": "eda94995-e03b-4b01-f26d-202e1b4449cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка (замена): 'Субъектом' → Должно быть: '﻿Субъектом'\n",
            "Ошибка (замена): '6' → Должно быть: 'б'\n",
            "Ошибка (замена): '«исследователь»' → Должно быть: 'исследователь'\n",
            "Ошибка (замена): 'социальноценностный' → Должно быть: 'социально-ценностный'\n",
            "Ошибка (лишнее): '--' → Должно быть: '[не должно быть]'\n",
            "Ошибка (замена): '«Закон' → Должно быть: 'Закон'\n",
            "Ошибка (замена): 'добродетели»' → Должно быть: 'добродетели1'\n",
            "Ошибка (замена): 'В Шершеневич' → Должно быть: 'Шершейевич'\n",
            "Ошибка (замена): 'оппози' → Должно быть: 'оппози-'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**РЕЗУЛЬТАТ:**\n",
        "\n",
        "Из анализа видно, что больше всего ошибок составляют OCR-ошибки. Например:\n",
        "- 'паиболее' → Должно быть: 'наиболее'\n",
        "- 'нище' → Должно быть: 'нише'\n",
        "- 'ктото' → Должно быть: 'кто-то'\n",
        "- 'спаружи' → Должно быть: 'снаружи'\n",
        "\n",
        "Таким образом, вижу необходимость дообучить модель **на синтетически сгенерированных OCR-ошибках**.\n"
      ],
      "metadata": {
        "id": "LsFhaX9JkaXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции для расчета метрик WER и CER"
      ],
      "metadata": {
        "id": "HNlzyuYtOu_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Функция для обработки текста для CER\n",
        "    Приводит текст к нижнему регистру и удаляет знаки препинания и пробелы.\n",
        "    \"\"\"\n",
        "    return ''.join(c.lower() for c in text if c not in string.punctuation and not c.isspace())"
      ],
      "metadata": {
        "id": "_IITIIlHMCK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_wer_cer(etalon_text, recognized_text):\n",
        "    \"\"\"\n",
        "    Вычисление метрик CER и WER\n",
        "    \"\"\"\n",
        "    # Обработка текстов для CER\n",
        "    etalon_text_prep = preprocess_text(etalon_text)\n",
        "    recognized_text_prep = preprocess_text(recognized_text)\n",
        "\n",
        "    # Вычисление CER и WER\n",
        "    wer = jiwer.wer(etalon_text, recognized_text)\n",
        "    cer = jiwer.cer(etalon_text_prep, recognized_text_prep)\n",
        "\n",
        "    return round(wer, 3), round(cer, 3)"
      ],
      "metadata": {
        "id": "gpgxvBPOy3p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Подготовка текста для дообучения**"
      ],
      "metadata": {
        "id": "o3Q1y_9ON_4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка текстов для генерации ошибок"
      ],
      "metadata": {
        "id": "MLJ1J4DgzmIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка текстов для обучения на 100 тысяч предложениях.**"
      ],
      "metadata": {
        "id": "joPPQe_7eyu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка файла Экономика**"
      ],
      "metadata": {
        "id": "nhGupYmnVYlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# путь к файлу\n",
        "text_path = '/content/drive/My Drive/Files_for_project/Books/economica_all.rtf'"
      ],
      "metadata": {
        "id": "ZBJo8FYYsTOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка RTF-файла\n",
        "with open(text_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    rtf_text = file.read()\n",
        "\n",
        "# Преобразование RTF в обычный текст\n",
        "text = rtf_to_text(rtf_text)\n",
        "print(text[0:4000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0NbgIh1pH2W",
        "outputId": "a38f5184-377a-4d5a-c730-57b9ae348752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Институты.\n",
            "Существует мнение, что институты — это не про Россию. Ведь институты — это некие правила.\n",
            "Если речь идет о формальных правилах, о законах, то в России закон что дышло, и жизнь тут идет не по законам. Может быть, она идет по каким-то неписаным правилам? Но очевидное соблюдение таких правил характерно там, где есть сообщества людей со своими обычаями или нормами поведения, например в деревне. Но вряд ли кто-то всерьез полагает, что мы соблюдаем правила русской деревни: три раза что-то предлагаем, два раза отказываемся и тому подобное. Похоже, что и эти правила в России не работают. Иногда говорят, что мы живем по понятиям (не случайно же с 1950-х страна слушает уголовную лирику). Конечно, «понятия» — тоже институт, неформальные правила, которые поддерживаются преступными сообществами. И такие сообщества в России прошли очень серьезную закалку, ведь они возникли и выживали в период тоталитаризма, в 1930–40-е годы (точно так же, как в Италии мафия необычайно укрепилась, кристаллизовалась и была доведена до алмазной твердости под давлением итальянского фашистского государства). Проблема в том, что и этот набор правил у нас не работает. Самое популярное слово в России — «беспредел». А беспредел как раз и означает, что не работают понятия.\n",
            "Некоторые государственные деятели, например Владислав Сурков, утверждают, что институтам в России не место: мол, чему нас учили великие русские философы Иван Ильин, Николай Бердяев? Они говорили, что в России нет институтов, а есть персоны. С одной стороны, отрицание институтов связано с несомненным эгоизмом власти, которой гораздо удобнее жить без правил, потому что для нее это достаточно «экономичная» позиция: как я решу, так и будет. С другой стороны, отрицание институтов во многом растет из нашего собственного сознания, из знаменитой русской смекалки. Ведь институт — это алгоритм, а если вы каждый раз готовы найти оригинальное решение, алгоритм вам не нужен.\n",
            "Почти полвека назад экономист и будущий нобелевский лауреат Дуглас Норт выдвинул лозунг: «Институты имеют значение». Наверное, ни в одной стране мира он не звучит так остро и спорно, как в России. Так имеют ли для нас значение институты? Или мы живем в каком-то внеинституциональном пространстве?\n",
            "\n",
            "Институты как удобство.\n",
            "\n",
            "Конечно, в России институты имеют значение. Мы используем их постоянно и очень активно. В первую очередь, потому что это удобно. Возьмем сферу принятия потребительских решений в условиях ограниченной рациональности: нам нужно сделать выбор, притом у нас совершенно точно нет возможности проанализировать все множество вариантов. Тут нам на помощь приходят простые правила, которые облегчают нашу задачу. Сто лет назад основоположник институционализма Торстейн Бунде Веблен открыл три таких правила, которые впоследствии были подтверждены эконометрически и получили название «эффекты Веблена».\n",
            "Первый эффект называется «демонстративным потреблением»: вы покупаете то, что дороже, потому что считаете, что оно по определению лучшее, и тем самым сокращаете для себя издержки выбора. В русском сознании этот принцип сформулирован в поговорке: «Дорого, да мило — дешево, да гнило» (кстати, абсолютно неверной с экономической точки зрения, потому что цена и качество не имеют однозначной связи).\n",
            "Второй вариант — «присоединение к большинству»: все так делают, и я так делаю. В советское время вы просто становились в самую длинную очередь, а уже потом спрашивали: «Чего дают?» Вы перекладывали на других издержки поиска и принятия решения о том, что для вас является самым необходимым. Эта очередь длиннее — значит, там дают то, что нужнее всего или редко встречается.\n",
            "Третий вариант — «феномен сноба»: вы покупаете то, что не покупает никто. Вы опять резко снижаете для себя издержки, потому что вам не надо преодолевать очереди, тратить время и прочие ресурсы. Но «феномен сноба» — это еще и способ выделения, как желтая кофта Маяковского или шарфик Пиотровского.\n",
            "Таким образом, если вы не намерены становиться товароведом и заниматься длительным\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_hyphens(text):\n",
        "    '''Убрает переносы'''\n",
        "    # Убираем переносы слов, заменяя '-\\n' на пустую строку\n",
        "    text = re.sub(r'-\\n', '', text)\n",
        "    # Убираем переносы строк, если они не следуют за переносом слова\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "0no4au7UwCmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_econom = remove_hyphens(text) # убираем переносы\n",
        "print(text_econom[0:5000]) # печать части текста, для проверки"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EEe5B0ewDF5",
        "outputId": "6639c8a1-9328-434a-fb41-254693f21167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Институты. Существует мнение, что институты — это не про Россию. Ведь институты — это некие правила. Если речь идет о формальных правилах, о законах, то в России закон что дышло, и жизнь тут идет не по законам. Может быть, она идет по каким-то неписаным правилам? Но очевидное соблюдение таких правил характерно там, где есть сообщества людей со своими обычаями или нормами поведения, например в деревне. Но вряд ли кто-то всерьез полагает, что мы соблюдаем правила русской деревни: три раза что-то предлагаем, два раза отказываемся и тому подобное. Похоже, что и эти правила в России не работают. Иногда говорят, что мы живем по понятиям (не случайно же с 1950-х страна слушает уголовную лирику). Конечно, «понятия» — тоже институт, неформальные правила, которые поддерживаются преступными сообществами. И такие сообщества в России прошли очень серьезную закалку, ведь они возникли и выживали в период тоталитаризма, в 1930–40-е годы (точно так же, как в Италии мафия необычайно укрепилась, кристаллизовалась и была доведена до алмазной твердости под давлением итальянского фашистского государства). Проблема в том, что и этот набор правил у нас не работает. Самое популярное слово в России — «беспредел». А беспредел как раз и означает, что не работают понятия. Некоторые государственные деятели, например Владислав Сурков, утверждают, что институтам в России не место: мол, чему нас учили великие русские философы Иван Ильин, Николай Бердяев? Они говорили, что в России нет институтов, а есть персоны. С одной стороны, отрицание институтов связано с несомненным эгоизмом власти, которой гораздо удобнее жить без правил, потому что для нее это достаточно «экономичная» позиция: как я решу, так и будет. С другой стороны, отрицание институтов во многом растет из нашего собственного сознания, из знаменитой русской смекалки. Ведь институт — это алгоритм, а если вы каждый раз готовы найти оригинальное решение, алгоритм вам не нужен. Почти полвека назад экономист и будущий нобелевский лауреат Дуглас Норт выдвинул лозунг: «Институты имеют значение». Наверное, ни в одной стране мира он не звучит так остро и спорно, как в России. Так имеют ли для нас значение институты? Или мы живем в каком-то внеинституциональном пространстве?  Институты как удобство.  Конечно, в России институты имеют значение. Мы используем их постоянно и очень активно. В первую очередь, потому что это удобно. Возьмем сферу принятия потребительских решений в условиях ограниченной рациональности: нам нужно сделать выбор, притом у нас совершенно точно нет возможности проанализировать все множество вариантов. Тут нам на помощь приходят простые правила, которые облегчают нашу задачу. Сто лет назад основоположник институционализма Торстейн Бунде Веблен открыл три таких правила, которые впоследствии были подтверждены эконометрически и получили название «эффекты Веблена». Первый эффект называется «демонстративным потреблением»: вы покупаете то, что дороже, потому что считаете, что оно по определению лучшее, и тем самым сокращаете для себя издержки выбора. В русском сознании этот принцип сформулирован в поговорке: «Дорого, да мило — дешево, да гнило» (кстати, абсолютно неверной с экономической точки зрения, потому что цена и качество не имеют однозначной связи). Второй вариант — «присоединение к большинству»: все так делают, и я так делаю. В советское время вы просто становились в самую длинную очередь, а уже потом спрашивали: «Чего дают?» Вы перекладывали на других издержки поиска и принятия решения о том, что для вас является самым необходимым. Эта очередь длиннее — значит, там дают то, что нужнее всего или редко встречается. Третий вариант — «феномен сноба»: вы покупаете то, что не покупает никто. Вы опять резко снижаете для себя издержки, потому что вам не надо преодолевать очереди, тратить время и прочие ресурсы. Но «феномен сноба» — это еще и способ выделения, как желтая кофта Маяковского или шарфик Пиотровского. Таким образом, если вы не намерены становиться товароведом и заниматься длительным анализом рынка, ваша свобода воли при принятии потребительского решения состоит в том, что вы выбираете между этими тремя правилами. Для вас это инструмент, который помогает перешагнуть через ступеньку, или шест, который позволяет взять высоту. И воля ваша — хотите ли вы демонстрировать свой достаток или снобизм либо просто сделать так, как делают ваши коллеги, друзья и соседи. В любом случае вы поступаете рационально — вы решаете задачку.  Институты как принуждение.  Однако институты не сводятся к простому бытовому удобству. Взять то же самое демонстративное потребление, потрясшее Россию 1990-х (вспомните анекдоты про новых русских, которые расстраиваются из-за того, что продешевили с галстуком, ведь за углом такой же стоит вдвое дороже). Это не просто выбор одной из трех возможных моделей поведения. Веблен говорил, что демонстративное поведение — способ статусного утверждения, включенный в кредитные отношения, в денежную культуру в целом. Это выгодное поведение. При этом оно может б\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def qty_sentences(text):\n",
        "    '''Подсчет количества предложений'''\n",
        "    # Разделение текста на предложения по знакам конца предложения (., !, ?)\n",
        "    sentences = re.split(r'[.!?]\\s+', text)\n",
        "    # Подсчёт количества предложений\n",
        "    num_sentences = len(sentences)\n",
        "    print(f\"Количество предложений в тексте: {num_sentences}\")\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "tbQz7reo-MLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sentences(text, num_sentences):\n",
        "    '''Вывод предложений на экран'''\n",
        "    sentences = qty_sentences(text)\n",
        "    for sentence in sentences[:num_sentences]:\n",
        "        print(sentence.strip())"
      ],
      "metadata": {
        "id": "3EsKDH3UBKdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_sentences(text_econom, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jao2IYZE_n2z",
        "outputId": "89b4b374-9951-45da-9bf9-c113f280b921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество предложений в тексте: 980\n",
            "Институты\n",
            "Существует мнение, что институты — это не про Россию\n",
            "Ведь институты — это некие правила\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_texts_from_folder(folder_path, encoding='windows-1251'):\n",
        "    \"\"\"\n",
        "    Загружает все текстовые файлы из указанной папки\n",
        "\n",
        "    :param folder_path: путь к папке с файлами\n",
        "    :param encoding: кодировка файлов (по умолчанию windows-1251)\n",
        "    :return: словарь {имя_файла: содержимое}\n",
        "    \"\"\"\n",
        "    texts = {}\n",
        "    # Перебираем все файлы в папке\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        # Загружаем только текстовые файлы\n",
        "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
        "            with open(file_path, 'r', encoding=encoding) as file:\n",
        "                lines = [line.strip() for line in file.readlines()]\n",
        "                text = '\\n'.join(lines)\n",
        "                # Ваша функция для обработки переносов\n",
        "                texts[filename] = remove_hyphens(text)\n",
        "    return texts"
      ],
      "metadata": {
        "id": "hYCkZPIe0fFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/Files_for_project/Books_100/'\n",
        "all_texts = load_texts_from_folder(folder_path)\n",
        "# Печатаем имена загруженных файлов и первые 3 предложения\n",
        "for name, text in all_texts.items():\n",
        "    print(f\"\\nФайл: {name}\")\n",
        "    print(f\"Начало текста: {text[:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX1bM8omfwNv",
        "outputId": "47a004ef-0b35-4963-90b5-e892f25ca8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Файл: Frayi_Labirintyi_Eho.txt\n",
            "Начало текста: Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственно...\n",
            "\n",
            "Файл: Sanderson_Legion.txt\n",
            "Начало текста: Психология как суперсила – тема, которая в моих произведениях повторяется снова и снова. Я всегда сч...\n",
            "\n",
            "Файл: Akunin_Nefritovyie_Chetki.txt\n",
            "Начало текста: На похоронах человека, который собирался стать буддой, публики было до неприличного мало. Из компатр...\n",
            "\n",
            "Файл: Simmons_Giperion.txt\n",
            "Начало текста: Консул Гегемонии сидел на балконе своего эбеново-черного космического корабля и на хорошо сохранивше...\n",
            "\n",
            "Файл: Aristotel_Ritorika.txt\n",
            "Начало текста: Аристотель – величайший ученый своего времени, философ и практик, работы которого стали основой разв...\n",
            "\n",
            "Файл: Lukyanenko_Dozoryi.txt\n",
            "Начало текста: Эскалатор полз медленно, натужно. Старая станция, ничего не поделаешь. Зато ветер гулял в бетонной т...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Объединить тексты без разделителей и удалить '\\xa0'\n",
        "combined_text_100 = \"\".join(all_texts.values())\n",
        "combined_text_100 = combined_text_100.replace('\\xa0', '')\n",
        "print(combined_text_100[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ8K2Xi_hAG9",
        "outputId": "fa57e255-b63b-4037-e12e-e8985ee6dc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# соединение с файлом по экономике\n",
        "total_text_100 = \" \".join([combined_text_100, text_econom])"
      ],
      "metadata": {
        "id": "j-jZBVFxfwev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_sentences(total_text_100, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7URxKUvfwcc",
        "outputId": "1b4dbe50-ead4-4aaa-c209-efa42de74f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество предложений в тексте: 126877\n",
            "Меня действительно зовут Макс\n",
            "Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени\n",
            "Я родом откуда-то из этих мест\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка текстов для обучения на 200 тысяч предложениях.**"
      ],
      "metadata": {
        "id": "j3t3oO-ofmz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Загрузка художественных книг:*\n",
        "\n",
        "- Макс Фрай. Лабиринты Ехо\n",
        "- Акунин. Нефритовые четки\n",
        "- Хейли. Отель\n",
        "- Сандерсон. Легион\n",
        "- Аристотель. Риторика\n",
        "- Дефо. Робинзон Крузо\n",
        "- Сервантес. Дон Кихот\n",
        "- Верн. Таинственный остров\n",
        "- Симмонс. Гипперион\n",
        "- Лукьяненко. Дозоры\n",
        "- Гейман. Благие знамения\n",
        "- Адамс. Автостопом по галактике, 2 части\n"
      ],
      "metadata": {
        "id": "ZPgIbky7gpHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/Files_for_project/Books/'\n",
        "all_texts = load_texts_from_folder(folder_path)\n",
        "# Печатаем имена загруженных файлов и первые 3 предложения\n",
        "for name, text in all_texts.items():\n",
        "    print(f\"\\nФайл: {name}\")\n",
        "    print(f\"Начало текста: {text[:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suBwMlHK0sJU",
        "outputId": "c10a41ef-267d-4e35-95df-0c7098034444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Файл: Frayi_Labirintyi_Eho.txt\n",
            "Начало текста: Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственно...\n",
            "\n",
            "Файл: Heyili_Otel.txt\n",
            "Начало текста: 1  «Будь на то моя воля, – думал Питер Макдермотт, – я давным-давно выгнал бы этого начальника охран...\n",
            "\n",
            "Файл: Akunin_Nefritovyie_Chetki.txt\n",
            "Начало текста: На похоронах человека, который собирался стать буддой, публики было до неприличного мало. Из компатр...\n",
            "\n",
            "Файл: Sanderson_Legion.txt\n",
            "Начало текста: Психология как суперсила – тема, которая в моих произведениях повторяется снова и снова. Я всегда сч...\n",
            "\n",
            "Файл: Aristotel_Ritorika.txt\n",
            "Начало текста: Аристотель – величайший ученый своего времени, философ и практик, работы которого стали основой разв...\n",
            "\n",
            "Файл: Defo_Robinzon_Kruzo.txt\n",
            "Начало текста: Если существует на свете история приключений частного лица, заслуживающая стать всеобщим достоянием ...\n",
            "\n",
            "Файл: Vern_Tainstvennyiyi_Ostrov.txt\n",
            "Начало текста: – Мы поднимаемся?  – Нет, наоборот, мы опускаемся!  – Хуже, мистер Сайрес, мы падаем!  – Ради бога, ...\n",
            "\n",
            "Файл: Servantes_Don_Kihot.txt\n",
            "Начало текста: В скромной деревушке провинции Ламанчи жил идальго [1 - Дворянин в средневековой Испании.] по имени ...\n",
            "\n",
            "Файл: Simmons_Giperion.txt\n",
            "Начало текста: Консул Гегемонии сидел на балконе своего эбеново-черного космического корабля и на хорошо сохранивше...\n",
            "\n",
            "Файл: Lukyanenko_Dozoryi.txt\n",
            "Начало текста: Эскалатор полз медленно, натужно. Старая станция, ничего не поделаешь. Зато ветер гулял в бетонной т...\n",
            "\n",
            "Файл: Geyiman_Blagie_Znameniya.txt\n",
            "Начало текста: Добрые предзнаменования #1 Говорят, мир закончится в субботу. А именно, в следующую субботу. Незадол...\n",
            "\n",
            "Файл: Adams_Avtostopom_1.txt\n",
            "Начало текста: Каждое утро традиционный душераздирающий вопль оповещал окрестности, что Артур Дент проснулся и зано...\n",
            "\n",
            "Файл: Adams_Avtostopom_2.txt\n",
            "Начало текста: Далеко-далеко, в не замеченных картографами складках давно вышедшего из моды Западного Спирального Р...\n",
            "\n",
            "Файл: Akunin_Ne_Proshayus.txt\n",
            "Начало текста: На исходе дня, уже в сумерках, вокзал вдруг пришел в движение. Разнесся слух, что будет поезд на Мос...\n",
            "\n",
            "Файл: Akunin_Prosto_Masa.txt\n",
            "Начало текста: Тацумаса проснулся на несколько минут раньше обычного – над ухом нудел комар. Вот уже и лето, пора ж...\n",
            "\n",
            "Файл: Akunin_Ves_Mir_Teatr.txt\n",
            "Начало текста: Гармоническим человеком Эраст Петрович стал себя считать с того момента, когда достиг первой ступень...\n",
            "\n",
            "Файл: Akunin_Planeta_Voda.txt\n",
            "Начало текста: Океанский пароход «Юниверс», следовавший рейсом из Марселя в Буэнос-Айрес, шел мимо Канарских остров...\n",
            "\n",
            "Файл: Akunin_Almaznaya_KolesnicaI.txt\n",
            "Начало текста: В тот день, когда ужасный разгром русского флота у острова Цусима приближался к концу и когда об это...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Объединить тексты без разделителей и удалить '\\xa0'\n",
        "combined_text = \"\".join(all_texts.values())\n",
        "combined_text = combined_text.replace('\\xa0', '')\n",
        "print(combined_text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwGbzpUpH_Eq",
        "outputId": "03d92de4-61b3-4270-9132-2de95ffaf67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_sentences(combined_text, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzZR40C9Mokh",
        "outputId": "3ce89f73-f74a-4e56-d38d-12755cd2c590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество предложений в тексте: 243054\n",
            "Меня действительно зовут Макс\n",
            "Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени\n",
            "Я родом откуда-то из этих мест\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_text = \" \".join([combined_text, text_econom])  # соединение с файлом по экономике"
      ],
      "metadata": {
        "id": "4fOyWK9FRqWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIEV2tO9eeCh",
        "outputId": "8f7239fe-6d9c-4708-9132-9da7d0d74315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени.  Я родом откуда-то из этих мест. Возможно даже, ваш бывший сосед. Я прожил здесь около тридцати лет, пока не попал в Ехо.  Вы не найдете город Ехо ни на одной карте. Потому как Ехо находится не на этой планете. Точнее сказать, не в этом Мире. Второе определение мне нравится больше, поскольку выражение «не на этой планете» неизбежно ассоциируется с полетами на космических кораблях, чего со мной, по счастию, никогда не происходило. Подробный отчет о моем путешествии в Ехо вы найдете в одной из историй, за которые приметесь после того, как покончите с предисловием. Она называется «Чужак».  Итак, город Ехо – это столица Соединенного Королевства Угуланда, Гугланда, Ландаланда и Уриуланда, а также графств Шимара и Вук, земель Благостного Ордена Семилистника, вольного города Гажин и острова Муримах.  Далее. Законы природы этого Мира не только допускают, но даже провоцируют развитие та\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_sentences(total_text, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRfpJTf2RqZe",
        "outputId": "593605d7-6d5e-438b-9099-551491f48d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество предложений в тексте: 244033\n",
            "Меня действительно зовут Макс\n",
            "Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени\n",
            "Я родом откуда-то из этих мест\n",
            "Возможно даже, ваш бывший сосед\n",
            "Я прожил здесь около тридцати лет, пока не попал в Ехо\n",
            "Вы не найдете город Ехо ни на одной карте\n",
            "Потому как Ехо находится не на этой планете\n",
            "Точнее сказать, не в этом Мире\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**РЕЗУЛЬТАТ:**\n",
        "\n",
        "Загружены тексты для генерации ошибок, объединены в один файл, и разделен на отдельные предложения.  \n",
        "\n",
        "Сделано 2 варианта по объему текста: на 126877 и 244041 предложение."
      ],
      "metadata": {
        "id": "W6cenTU9cAKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация OCR-ошибок"
      ],
      "metadata": {
        "id": "aFTFx9vpzvUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для генерации OCR-ошибок использованы самые распространенные варианты ошибок и объединены в словарь."
      ],
      "metadata": {
        "id": "oB_NmYrE5RrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Словарь для замены символов\n",
        "# (ключ: правильный символ, значение: список возможных замен)\n",
        "OCR_ERRORS = {\n",
        "    \"о\": [\"0\", \"а\"],\n",
        "    \"а\": [\"@\", \"о\"],\n",
        "    \"е\": [\"ё\"],\n",
        "    \"ё\": [\"е\"],\n",
        "    \"ш\": [\"щ\"],\n",
        "    \"м\": [\"п\"],\n",
        "    \"г\": [\"т\"],\n",
        "    \"т\": [\"г\"],\n",
        "    \"с\": [\"е\", \"о\"],\n",
        "    \"у\": [\"ц\", \"ч\"],\n",
        "    \"к\": [\"ж\", \"х\"],\n",
        "    \"х\": [\"к\", \"ж\"],\n",
        "    \"ъ\": [\"ь\"],\n",
        "    \"ь\": [\"ъ\"],\n",
        "    \"й\": [\"и\"],\n",
        "    \"и\": [\"н\", \"й\"],\n",
        "    \"н\": [\"и\", \"п\"],\n",
        "    \"в\": [\"8\", \"ь\", \"ъ\"],\n",
        "    \"а\": [\"@\"],\n",
        "    \"з\": [\"3\"],\n",
        "    \"ч\": [\"4\"],\n",
        "    \"б\": [\"6\"],\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "MWXZNLSJBbkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ocr_errors(text, error_prob=0.1, max_errors_per_word=1):\n",
        "    \"\"\"\n",
        "    Генерирует OCR-ошибки в тексте с ограничением на количество ошибок в слове.\n",
        "    :param text: Исходный текст.\n",
        "    :param error_prob: Вероятность ошибки для каждого символа.\n",
        "    :param max_errors_per_word: Максимальное количество ошибок в одном слове.\n",
        "    :return: Текст с ошибками.\n",
        "    \"\"\"\n",
        "    words = text.split(' ')\n",
        "    result = []\n",
        "\n",
        "    for word in words:\n",
        "        # Счетчик ошибок в текущем слове\n",
        "        error_count = 0\n",
        "        modified_word = []\n",
        "\n",
        "        for char in word:\n",
        "            # Проверяем условия для добавления ошибки\n",
        "            if (char.lower() in OCR_ERRORS and\n",
        "                random.random() < error_prob and\n",
        "                error_count < max_errors_per_word):\n",
        "                # Заменяем символ на случайный из списка возможных замен\n",
        "                replacement = random.choice(OCR_ERRORS[char.lower()])\n",
        "                # Сохраняем регистр\n",
        "                if char.isupper():\n",
        "                    replacement = replacement.upper()\n",
        "                modified_word.append(replacement)\n",
        "                error_count += 1\n",
        "            else:\n",
        "                modified_word.append(char)\n",
        "\n",
        "        result.append(''.join(modified_word))\n",
        "\n",
        "    return ' '.join(result)"
      ],
      "metadata": {
        "id": "_tKkaGnBiXWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Датасет на 100 тысяч предложений.**"
      ],
      "metadata": {
        "id": "cY-ednKWhtZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация 10% вероятность ошибки\n",
        "noisy_text_100 = generate_ocr_errors(total_text_100, error_prob=0.1)\n",
        "print(f\"Исходный текст:   {total_text_100[0:3000]}\")\n",
        "print(f\"Текст с ошибками: {noisy_text_100[0:3000]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__RBb61sjTrM",
        "outputId": "851d1897-9ddf-4d40-d259-8196f93dd5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст:   Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени.  Я родом откуда-то из этих мест. Возможно даже, ваш бывший сосед. Я прожил здесь около тридцати лет, пока не попал в Ехо.  Вы не найдете город Ехо ни на одной карте. Потому как Ехо находится не на этой планете. Точнее сказать, не в этом Мире. Второе определение мне нравится больше, поскольку выражение «не на этой планете» неизбежно ассоциируется с полетами на космических кораблях, чего со мной, по счастию, никогда не происходило. Подробный отчет о моем путешествии в Ехо вы найдете в одной из историй, за которые приметесь после того, как покончите с предисловием. Она называется «Чужак».  Итак, город Ехо – это столица Соединенного Королевства Угуланда, Гугланда, Ландаланда и Уриуланда, а также графств Шимара и Вук, земель Благостного Ордена Семилистника, вольного города Гажин и острова Муримах.  Далее. Законы природы этого Мира не только допускают, но даже провоцируют развитие так называемых «паранормальных» способностей у всего населения. Особенно у нас, в Ехо, поскольку этот город был построен в Сердце Мира – если пользоваться терминологией местных магов, не прибегая к которой, я и вовсе ничего не смогу объяснить. Если за пределами Угуланда (провинции, в центре которой построен Ехо) дело не заходит дальше какой-нибудь телепатии и прочих пустяков, то у нас все гораздо серьезнее. Колдовать в Ехо не сможет только ленивый. Я вон и то научился, с пугающей меня самого легкостью.  Соответственно, местное население повально увлечено так называемой Очевидной, или «бытовой» магией. Вернее, было увлечено до наступления Эпохи Кодекса, приход которой предварялся трагическими и кровавыми событиями.  Еще в древности некоторые здешние мудрецы предрекали, что чрезмерное увлечение Очевидной магией может привести к трагическим последствиям. Существовала даже теория о возможном «конце света», мрачная и запутанная. Но отказаться от применения магии в то время было невозможно. Многочисленные магические Ордена, все как один чрезвычайно могущественные, на протяжении тысячелетий пытались поделить власть в государстве. Король же, какое бы имя он ни носил, в ту эпоху был не самой значительной фигурой в их напряженной политической игре.  Это продолжалось, пока престол не занял Гуриг VII – человек, перекроивший историю. Он нашел единственного союзника, на которого стоило ставить. Древний Орден Семилистника не только мечтал устранить многочисленных конкурентов, но с давних времен занимался серьезным изучением эсхатологических проблем. Великий Магистр Ордена Нуфлин Мони Мах был одним из тех мудрецов, кто вовремя понял, что катастрофа приближается, и с момента своего вступления в должность начал подготовку к серьезной борьбе с остальными Орденами. Объединившись с Гуригом VII, Орден Семилистника развязал «войну против всех», вошедшую в историю как Смутные Времена. Безумное столетие закончилось сокрушительной совместной победой Короля и Ордена Семилистника. В тот же день \n",
            "Текст с ошибками: Меия действительно зовут Пакс. Околько себя помню, всегда предпочитал сокращенный 8ариант собственного имени.  Я родом огкуда-то из этих мест. 8озможно д@же, ваш 6ывший сосед. Я прожил 3десь около тридцати лёт, пока не попал в Ехо.  Вы не найдете город Ёхо ни на однои карте. Потому как Еко нажодится не на этой планете. Точнее сказать, не в этом Мире. Второе определение мне нр@вится больше, посколъку выражение «ие на этай планете» неизбёжно ассоциируегся е полет@ми па жосмических кора6лях, чего со мной, п0 счасгию, никогда не происходило. Подробный отчет 0 моем пчтешествии в Ехо 8ы найдете в одной из нсторий, за к0торые приметесъ пасле гого, как покончите е предйсловием. 0на называется «Чужак».  Итак, город Ёхо – это столица Соединенного Королеветва Утуланда, Гугланд@, Ланд@ланда и Уриуланда, а также графств Шимар@ и Вук, земёль Благостного 0рдена Сепилистника, вольного города Гажин и осгрова Муримах.  Далеё. З@коны природы этого Мира не только допуокают, но д@же проьоцируют развитие таж называемых «паранормальных» споеобностей у всего населения. Особённо у нас, в Ехо, поскольку этот город был построен в Еердце Пира – ёсли пользоваться терминалогией местнык м@гов, не прибегая х которой, я и вовсе ничего не спогу объяснить. Если за пределами Угуланд@ (про8инции, в центре хоторой п0строен Ехо) дело пе заходит дальше какои-нибудь телеп@тии и прочих пуетяков, то у н@с ьсе гораздо серье3нее. Колдоьать в Ехо ие см0жет тольхо ленивый. Я вон и то научился, о пугающей меня самога легкосгью.  Соответственно, местное население повально увлечено тах н@зываемой Очевидной, йли «6ытовой» магйей. Вернее, было увлёчено д0 наступления Эпохи К0декса, приход которои прёдварялся трагическими й кровавыми событиями.  Еще в древнасти нехоторые здешние мудрецы предрекали, что чрезмерное увлечениё Ачевидной магией может привести к тратическим последст8иям. Существовала даже тёория 0 возможном «концё света», мрачн@я и запут@нная. Но отка3аться от примёнения магии в то время было неъозможно. Многочисленные магические Ордепа, вое как один чрезвычайно могущесгвенные, на протяжении тысячелетий пытались поделить вл@сть в госчдарстве. Хороль же, какое бы имя он ни н0сил, в ту эп0ху был не сапой зиачительной фигурой в йх н@пряженной политической итре.  Это продалжалось, пока престол не заиял Гуриг VII – чёловек, пёрекроивший исгорию. Он нащел единственного союзника, на котарого ст0ило ставить. Дреъний Арден Семилистника не только мёчтал устранигь многочисленных конкурентав, но с давннх времен занимался сёрьезным изучением эсхатологических проблем. Великий Магистр Ардена Нуфлйн Мони Мах был одним из тех мудрецоь, кто ьовремя понял, чта катастрофа приближ@ется, и с момента своего ьступления в должиость н@чал подготовку к серьезной борьбе с остальными Орденами. Объединившись е Гуритом VII, Орден Семилистника развязал «в0йну пратив всёх», вошедшую в иоторию хак Смутные Времена. Безумное сталетие зажончилось сокрушительной совместнай п0бедой Короля й Ордена Семилистника. В тат же день \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст на предложения\n",
        "def divide_sentences(text):\n",
        "    sentences = re.split(r'[.!?]\\s+', text)\n",
        "    sentences = list(map(lambda x: x.replace(\"\\xa0\", \" \"), sentences))\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "ZqVxm4TamBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем датасет\n",
        "dataset_total_100 = Dataset.from_dict({\n",
        "    \"source\": divide_sentences(noisy_text_100),  # Текст с ошибками\n",
        "    \"correction\": divide_sentences(total_text_100)  # Исправленный текст\n",
        "})\n",
        "print(dataset_total_100[0:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ52qO4VhtxR",
        "outputId": "95e568ca-faf4-420c-a2f5-c331b4ff7103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': ['Меия действительно зовут Пакс', 'Околько себя помню, всегда предпочитал сокращенный 8ариант собственного имени', 'Я родом огкуда-то из этих мест', '8озможно д@же, ваш 6ывший сосед', 'Я прожил 3десь около тридцати лёт, пока не попал в Ехо', 'Вы не найдете город Ёхо ни на однои карте', 'Потому как Еко нажодится не на этой планете', 'Точнее сказать, не в этом Мире', 'Второе определение мне нр@вится больше, посколъку выражение «ие на этай планете» неизбёжно ассоциируегся е полет@ми па жосмических кора6лях, чего со мной, п0 счасгию, никогда не происходило', 'Подробный отчет 0 моем пчтешествии в Ехо 8ы найдете в одной из нсторий, за к0торые приметесъ пасле гого, как покончите е предйсловием', '0на называется «Чужак»', 'Итак, город Ёхо – это столица Соединенного Королеветва Утуланда, Гугланд@, Ланд@ланда и Уриуланда, а также графств Шимар@ и Вук, земёль Благостного 0рдена Сепилистника, вольного города Гажин и осгрова Муримах', 'Далеё', 'З@коны природы этого Мира не только допуокают, но д@же проьоцируют развитие таж называемых «паранормальных» споеобностей у всего населения', 'Особённо у нас, в Ехо, поскольку этот город был построен в Еердце Пира – ёсли пользоваться терминалогией местнык м@гов, не прибегая х которой, я и вовсе ничего не спогу объяснить'], 'correction': ['Меня действительно зовут Макс', 'Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени', 'Я родом откуда-то из этих мест', 'Возможно даже, ваш бывший сосед', 'Я прожил здесь около тридцати лет, пока не попал в Ехо', 'Вы не найдете город Ехо ни на одной карте', 'Потому как Ехо находится не на этой планете', 'Точнее сказать, не в этом Мире', 'Второе определение мне нравится больше, поскольку выражение «не на этой планете» неизбежно ассоциируется с полетами на космических кораблях, чего со мной, по счастию, никогда не происходило', 'Подробный отчет о моем путешествии в Ехо вы найдете в одной из историй, за которые приметесь после того, как покончите с предисловием', 'Она называется «Чужак»', 'Итак, город Ехо – это столица Соединенного Королевства Угуланда, Гугланда, Ландаланда и Уриуланда, а также графств Шимара и Вук, земель Благостного Ордена Семилистника, вольного города Гажин и острова Муримах', 'Далее', 'Законы природы этого Мира не только допускают, но даже провоцируют развитие так называемых «паранормальных» способностей у всего населения', 'Особенно у нас, в Ехо, поскольку этот город был построен в Сердце Мира – если пользоваться терминологией местных магов, не прибегая к которой, я и вовсе ничего не смогу объяснить']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение с перемешиванием и фиксированным random_state\n",
        "dataset_total_100 = dataset_total_100.shuffle(seed=42)  # Перемешиваем данные\n",
        "dataset_total_100 = dataset_total_100.train_test_split(\n",
        "    test_size=0.2,\n",
        "    seed=42,  # Фиксируем random_state\n",
        "    shuffle=True  # Включено по умолчанию, но можно явно указать\n",
        ")\n",
        "\n",
        "# Проверка структуры\n",
        "print(dataset_total_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6gKlW-Nht2a",
        "outputId": "44160555-8d18-4cc0-ea72-5a973fe6950d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['source', 'correction'],\n",
            "        num_rows: 101501\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['source', 'correction'],\n",
            "        num_rows: 25376\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь для сохранения в Google Drive\n",
        "save_path_100 = '/content/drive/My Drive/Files_for_project/ocr_dataset_100'\n",
        "\n",
        "# Сохранение датасета\n",
        "dataset_total_100.save_to_disk(save_path_100)\n",
        "\n",
        "print(f\"Датасет сохранён в: {save_path_100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "56366bfa57264fe6b1cbc528baac58ba",
            "a14ebd789d944ad68b2a423f946de7bc",
            "5ef3ddc7e77647b9ad4b7cb4e25d201b",
            "2d7df564d12246569d9b31339481f036",
            "e216dc4180484386bd1333853fb3f7dd",
            "0a60097c98c74159900ecfe3f896937f",
            "a50e2cde66604684b7136a4b1197e425",
            "e4f0904e4f7e4f30bf8f78e21ab49338",
            "e5bd0151a5884aac94ae87ce80a7c2cb",
            "d6d7cdd3deb24b279cc59fd105279103",
            "39c09364b6dd4fa4977a1b07ce701c6b",
            "f7c45f2658984f139542a5a593c75121",
            "6790b988d61c42609b13624e0a6dca88",
            "1c3c50b915cf4dce8a82b61708dc6467",
            "9eff5018156842f6ae605f054de75549",
            "cfff58e806294d28a427fcea3c253c70",
            "d2328e762b6b4043b600fe6e300be087",
            "23a4993876c24777b390ed5446cde977",
            "28857ee9c81142d1aadb2fe32996b466",
            "4a54b7f8e4014a3bbd64a71677032d01",
            "7d88f5168bdd4a6fadd0865520d8032a",
            "711dbfd1422c4b40864e10a253c9f835"
          ]
        },
        "id": "HH7I9Dw1ht5Y",
        "outputId": "4c88d878-84db-4536-d0aa-739fcb1a277a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/101501 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56366bfa57264fe6b1cbc528baac58ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/25376 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7c45f2658984f139542a5a593c75121"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датасет сохранён в: /content/drive/My Drive/Files_for_project/ocr_dataset_100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**РЕЗУЛЬТАТ:**\n",
        "\n",
        "Сгенерированы самые распространенные OCR-ошибки для русского языка с вероятностью ошибки 10% на основе оригинального текста размером более 100 тысяч предложений."
      ],
      "metadata": {
        "id": "b5_QXIt4jmrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Датасет на 200 тысяч предложений.**"
      ],
      "metadata": {
        "id": "3dN8p3-qh2PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация 10% вероятность ошибки\n",
        "noisy_text = generate_ocr_errors(total_text, error_prob=0.1)\n",
        "print(f\"Исходный текст:   {total_text[0:3000]}\")\n",
        "print(f\"Текст с ошибками: {noisy_text[0:3000]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1npaK8YZhtux",
        "outputId": "4854463e-0918-4ecc-e357-cf8f7c595cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст:   Меня действительно зовут Макс. Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени.  Я родом откуда-то из этих мест. Возможно даже, ваш бывший сосед. Я прожил здесь около тридцати лет, пока не попал в Ехо.  Вы не найдете город Ехо ни на одной карте. Потому как Ехо находится не на этой планете. Точнее сказать, не в этом Мире. Второе определение мне нравится больше, поскольку выражение «не на этой планете» неизбежно ассоциируется с полетами на космических кораблях, чего со мной, по счастию, никогда не происходило. Подробный отчет о моем путешествии в Ехо вы найдете в одной из историй, за которые приметесь после того, как покончите с предисловием. Она называется «Чужак».  Итак, город Ехо – это столица Соединенного Королевства Угуланда, Гугланда, Ландаланда и Уриуланда, а также графств Шимара и Вук, земель Благостного Ордена Семилистника, вольного города Гажин и острова Муримах.  Далее. Законы природы этого Мира не только допускают, но даже провоцируют развитие так называемых «паранормальных» способностей у всего населения. Особенно у нас, в Ехо, поскольку этот город был построен в Сердце Мира – если пользоваться терминологией местных магов, не прибегая к которой, я и вовсе ничего не смогу объяснить. Если за пределами Угуланда (провинции, в центре которой построен Ехо) дело не заходит дальше какой-нибудь телепатии и прочих пустяков, то у нас все гораздо серьезнее. Колдовать в Ехо не сможет только ленивый. Я вон и то научился, с пугающей меня самого легкостью.  Соответственно, местное население повально увлечено так называемой Очевидной, или «бытовой» магией. Вернее, было увлечено до наступления Эпохи Кодекса, приход которой предварялся трагическими и кровавыми событиями.  Еще в древности некоторые здешние мудрецы предрекали, что чрезмерное увлечение Очевидной магией может привести к трагическим последствиям. Существовала даже теория о возможном «конце света», мрачная и запутанная. Но отказаться от применения магии в то время было невозможно. Многочисленные магические Ордена, все как один чрезвычайно могущественные, на протяжении тысячелетий пытались поделить власть в государстве. Король же, какое бы имя он ни носил, в ту эпоху был не самой значительной фигурой в их напряженной политической игре.  Это продолжалось, пока престол не занял Гуриг VII – человек, перекроивший историю. Он нашел единственного союзника, на которого стоило ставить. Древний Орден Семилистника не только мечтал устранить многочисленных конкурентов, но с давних времен занимался серьезным изучением эсхатологических проблем. Великий Магистр Ордена Нуфлин Мони Мах был одним из тех мудрецов, кто вовремя понял, что катастрофа приближается, и с момента своего вступления в должность начал подготовку к серьезной борьбе с остальными Орденами. Объединившись с Гуригом VII, Орден Семилистника развязал «войну против всех», вошедшую в историю как Смутные Времена. Безумное столетие закончилось сокрушительной совместной победой Короля и Ордена Семилистника. В тот же день \n",
            "Текст с ошибками: Мёня действнтельно зовуг Макс. Сжолько себя памню, всетда предпочитал сокращеиный вариант с0бственного имени.  Я родом откуда-то из этих мест. Возможно д@же, ваш бывший сосед. Я прожил здесь окола тридцати лет, пока не попал в Ехо.  Вы нё найдёте г0род Ехо ни на одпой к@рте. Потому как Ёхо находится нё па этой планете. Точнеё сказ@ть, не в этоп Мире. Второе определепие пне нр@вится больще, поскольку выражение «нё н@ этой планеге» нейзбежно ассоциируется с полетамй на космичёских кор@блях, 4его со пной, по счастию, ник0гда не происходило. Подробный отчег о моем путешествин в Ех0 вы найдете в одной из историй, за которые приметесь после того, как покон4ите о предиоловием. Она называется «Чужак».  Итак, город Ехо – эго сголица Соединенпого Жоролевства Угуланда, Гугл@нда, Ландаланда и Уриуланд@, а гакже графств Шимара и Вук, земель Благостного Ордена Семилистнйка, вольного города Гажин и острова Мурим@х.  Далее. Законы природы этаго Мира не т0лько допускают, но даже провоцируют ра3витие таж называемых «параиормальных» способностёй у всего иаселения. Оообенно у нае, в Ехо, поскольку этот город был построен в Сёрдце Мира – если пользоваться терминологией местных магов, нё прибегая к каторой, я и вовсе ничего не смогц объясиить. Еслй за пределами Утуланда (провипции, в центре которой построен Ехо) дело пе заходит дальше к@кой-нибудь телепатии и прочих пустяков, то у нае все гораздо оерьезнее. Колдов@ть в Ехо не сможет только ленивыи. Я вон и то н@учился, с пугающей мёня самого легхостью.  Соотвегственно, мёстное население повально увлечено так иазываемой Очевидной, или «бытовой» магией. Верпее, было увлечёно до наступления Эпоки Кодекса, приход когорой предварялся трагическими и крававыми ообытиями.  Еще в дрёвности некоторые здешнйе мудрецы предрекали, что чрезмёрное цвлечение Очевидиой м@гией может привёсти к трагическим последствиям. Существовала даже те0рия о возможном «конце овета», мрачная и запутанная. Но отказаться от применения м@гии 8 го время было нево3можно. Многочислённые магичесхие Ордена, все к@к один чре3вычайно магущественные, на прогяжении тысячелетий пыгались подёлить влаоть в гасударстве. Жороль же, жакое бы имя он ни носил, в ту эпоху был не сапой значительной фигурой в их папряженной политической игрё.  Это продолжалось, п0ка престол не занял Гуриг VII – 4еловек, перёкроивший историю. Он нашел единствённого союзника, н@ котораго ст0ило ставить. Дрёвний Орден Семилистиика не только мечтал усгранить мпогочисленных конкурентов, но с давних времен занимался серьезным изучением эсхатолотических проблем. Великйй Магистр Ордена Нуфлии Мони Пах был адним из гех мудрецов, кто вовремя понял, что катасгрофа приближается, и о м0мента своего вступления в должность начал подготовку к серье3ной борьбе с оотальными Орденами. Объедииившись с Туригом VII, Орден Семйлистника развя3ал «воину против всех», вошедшую в иоторию как Смутные Времена. Безумиое сголетие зак0нчилось сокрушительнай совпестной победой Короля и Ордена Семилистнижа. В тот жё день \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем датасет\n",
        "dataset_total = Dataset.from_dict({\n",
        "    \"source\": divide_sentences(noisy_text),  # Текст с ошибками\n",
        "    \"correction\": divide_sentences(total_text)  # Исправленный текст\n",
        "})\n",
        "print(dataset_total[0:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BitWmF_z7DGX",
        "outputId": "2bbf5d7a-843e-4c5b-ddcb-9141bfb84e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': ['Мёня действнтельно зовуг Макс', 'Сжолько себя памню, всетда предпочитал сокращеиный вариант с0бственного имени', 'Я родом откуда-то из этих мест', 'Возможно д@же, ваш бывший сосед', 'Я прожил здесь окола тридцати лет, пока не попал в Ехо', 'Вы нё найдёте г0род Ехо ни на одпой к@рте', 'Потому как Ёхо находится нё па этой планете', 'Точнеё сказ@ть, не в этоп Мире', 'Второе определепие пне нр@вится больще, поскольку выражение «нё н@ этой планеге» нейзбежно ассоциируется с полетамй на космичёских кор@блях, 4его со пной, по счастию, ник0гда не происходило', 'Подробный отчег о моем путешествин в Ех0 вы найдете в одной из историй, за которые приметесь после того, как покон4ите о предиоловием', 'Она называется «Чужак»', 'Итак, город Ехо – эго сголица Соединенпого Жоролевства Угуланда, Гугл@нда, Ландаланда и Уриуланд@, а гакже графств Шимара и Вук, земель Благостного Ордена Семилистнйка, вольного города Гажин и острова Мурим@х', 'Далее', 'Законы природы этаго Мира не т0лько допускают, но даже провоцируют ра3витие таж называемых «параиормальных» способностёй у всего иаселения', 'Оообенно у нае, в Ехо, поскольку этот город был построен в Сёрдце Мира – если пользоваться терминологией местных магов, нё прибегая к каторой, я и вовсе ничего не смогц объясиить'], 'correction': ['Меня действительно зовут Макс', 'Сколько себя помню, всегда предпочитал сокращенный вариант собственного имени', 'Я родом откуда-то из этих мест', 'Возможно даже, ваш бывший сосед', 'Я прожил здесь около тридцати лет, пока не попал в Ехо', 'Вы не найдете город Ехо ни на одной карте', 'Потому как Ехо находится не на этой планете', 'Точнее сказать, не в этом Мире', 'Второе определение мне нравится больше, поскольку выражение «не на этой планете» неизбежно ассоциируется с полетами на космических кораблях, чего со мной, по счастию, никогда не происходило', 'Подробный отчет о моем путешествии в Ехо вы найдете в одной из историй, за которые приметесь после того, как покончите с предисловием', 'Она называется «Чужак»', 'Итак, город Ехо – это столица Соединенного Королевства Угуланда, Гугланда, Ландаланда и Уриуланда, а также графств Шимара и Вук, земель Благостного Ордена Семилистника, вольного города Гажин и острова Муримах', 'Далее', 'Законы природы этого Мира не только допускают, но даже провоцируют развитие так называемых «паранормальных» способностей у всего населения', 'Особенно у нас, в Ехо, поскольку этот город был построен в Сердце Мира – если пользоваться терминологией местных магов, не прибегая к которой, я и вовсе ничего не смогу объяснить']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic77EGZAmIrp",
        "outputId": "702dfca7-cd5a-44e3-b866-eaa506dbb16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['source', 'correction'],\n",
              "    num_rows: 244033\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создала датасет с текстом с ошибками и эталонным текстом. Разделим на train и test"
      ],
      "metadata": {
        "id": "_9pGYxaHMlwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение с перемешиванием и фиксированным random_state\n",
        "dataset_total = dataset_total.shuffle(seed=42)  # Перемешиваем данные\n",
        "dataset_total = dataset_total.train_test_split(\n",
        "    test_size=0.2,\n",
        "    seed=42,  # Фиксируем random_state\n",
        "    shuffle=True  # Включено по умолчанию, но можно явно указать\n",
        ")\n",
        "\n",
        "# Проверка структуры\n",
        "print(dataset_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUP5tbp_kNnB",
        "outputId": "15ab30ad-49b5-402e-9d2c-8292fdab6d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['source', 'correction'],\n",
            "        num_rows: 195226\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['source', 'correction'],\n",
            "        num_rows: 48807\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь для сохранения в Google Drive\n",
        "save_path = '/content/drive/My Drive/Files_for_project/ocr_dataset'\n",
        "\n",
        "# Сохранение датасета\n",
        "dataset_total.save_to_disk(save_path)\n",
        "\n",
        "print(f\"Датасет сохранён в: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "b0eab84f08164a44bbb0f9bfc85dd946",
            "386b3f5233c549a1a647452e7172c373",
            "c540d9ddc75b448eb1b8a52437f632ac",
            "a21b63f92e964886812848a3ff09dd6c",
            "f3aff65fa9cc4ade82284d2715e08eb9",
            "e16de9c6c56046fdb1514167dfb37827",
            "95f9b6f2734c4496a3e65a7903c514cb",
            "35aeef82ce0c494e973de5ccf4c43609",
            "baa64edce79745faafdb1e6c4a5ff742",
            "45ae9a3dfd7449e09c45c4562de48645",
            "cc24fd7cbde94ee0afb50aa59df186da",
            "bd537f676e8443ed9bfe3bc7942f5e02",
            "e34b0e6e9d3b42dc9098f95a08ffa60b",
            "4556122a35414d808dd2ff8ea9db2e08",
            "96bf133c8ee54e00af9bfbafafb9f7bf",
            "a58137e13cfe459fa902dbbac7f4b502",
            "a4b5170bc61545788fa178ea64af1530",
            "92d5e8b518d04486bd317d18d28e2100",
            "da9cf7be75e7413cb139521837c411b0",
            "7f7f9059dee8486995b53cc06224df72",
            "eef8aaae83d94f98915991323c46e651",
            "15cba50e98fa443489fa6db567f40c54"
          ]
        },
        "id": "1ei46f4a4LsZ",
        "outputId": "94dfcd91-ca1d-47ab-945f-526a8cc73749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/195226 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0eab84f08164a44bbb0f9bfc85dd946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/48807 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd537f676e8443ed9bfe3bc7942f5e02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датасет сохранён в: /content/drive/My Drive/Files_for_project/ocr_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**РЕЗУЛЬТАТ:**\n",
        "\n",
        "Сгенерированы самые распространенные OCR-ошибки для русского языка с вероятностью ошибки 10% на основе оригинального текста размером более 200 тысяч предложений."
      ],
      "metadata": {
        "id": "-2KVcDYwX511"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Дообучение моделей**"
      ],
      "metadata": {
        "id": "bYl3-h4QOJQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дообучение модели JamSpell"
      ],
      "metadata": {
        "id": "WMz6_vzj-SpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Дообучение на 100 тыс. предложениях.**"
      ],
      "metadata": {
        "id": "-OfBigIoq5ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Извлечь данные из DatasetDict. Преобразовать данные в формат, понятный JamSpell (список кортежей (текст с ошибками -> правильный текст)).\n",
        "\n"
      ],
      "metadata": {
        "id": "RlAokiIrkytC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация JamSpell и загрузка предобученной модели для 100 тыс.предлож.\n",
        "corrector_100 = jamspell.TSpellCorrector()\n",
        "corrector_100.LoadLangModel(\"ru_small.bin\")\n",
        "print(\"Предобученная модель 'ru_small.bin' успешно загружена!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26ed773-eb55-4805-806b-d9cac3b00162",
        "id": "2nnYu5KPq1Sl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предобученная модель 'ru_small.bin' успешно загружена!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_text(dataset, output_file):\n",
        "    \"\"\"\n",
        "    Экспортирует Dataset в текстовый файл. Каждая строка - исправленный текст.\n",
        "    \"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        #for sample in dataset_total['train']:\n",
        "        for sample in dataset:\n",
        "            ocr_text = sample['source']        # Текст с OCR-ошибками\n",
        "            correct_text = sample['correction']  # Эталонный текст\n",
        "            # Пишем пару OCR -> исправление\n",
        "            f.write(f\"{ocr_text} -> {correct_text}\\n\")"
      ],
      "metadata": {
        "id": "IBtOw_8oq1Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлекаем и сохраняем train/test в текстовые файлы на 100 тыс. предложений\n",
        "train_file_100 = \"train_100.txt\"\n",
        "test_file_100 = \"test_100.txt\"\n",
        "export_to_text(dataset_total_100[\"train\"], train_file_100)\n",
        "export_to_text(dataset_total_100[\"test\"], test_file_100)\n",
        "print(f\"Данные сохранены:\\n - Train: {train_file_100}\\n - Test: {test_file_100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a1e750-1a81-4964-faa2-e642917b491d",
        "id": "y4UxZPnDq1Sn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные сохранены:\n",
            " - Train: train_100.txt\n",
            " - Test: test_100.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение первых 5 строк из файла и вывод на экран\n",
        "with open(train_file_100, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(5):  # Чтение и вывод первых 5 строк\n",
        "        # Считываем строку и убираем лишние пробелы\n",
        "        line = file.readline().strip()\n",
        "        print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70019978-6276-49a7-c873-bd952701dd2b",
        "id": "0zejK0vPq1Sn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–Это ее гробница, отец -> –Это ее гробница, отец\n",
            "Славное местечко -> Славное местечко\n",
            "Ои тут же явился во главе толпы скульпторов -> Он тут же явился во главе толпы скульпторов\n",
            "Мне как-го довелось увидеть одпо нз 4удовищных пол0тен знаменигого придьорного живописца Гуриг@ VII – портрег боеваго тенерала Бубуты на фоне какой-то ъеликой битвы -> Мне как-то довелось увидеть одно из чудовищных полотен знаменитого придворного живописца Гурига VII – портрет боевого генерала Бубуты на фоне какой-то великой битвы\n",
            "–Пет -> –Нет\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Дообучение JamSpell на OCR-ошибках (с использованием тренировочного файла)\n",
        "alphabet_file = \"alphabet.txt\"\n",
        "with open(alphabet_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    alphabet = \"абвгдежзийклмнопрстуфхцчшщъыьэюяё\"\n",
        "    f.write(\"\\n\".join(alphabet))"
      ],
      "metadata": {
        "id": "NqKirFUfq1Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дообучить модель JamSpell на этих данных. Сохранить обновленную модель."
      ],
      "metadata": {
        "id": "GN-EqLu7q1Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Дообучение модели (на OCR-ошибках)\n",
        "model_file_100 = \"updated_ocr_model_100.bin\"\n",
        "corrector_100.TrainLangModel(train_file_100, alphabet_file, model_file_100)\n",
        "print(f\"Дообученная модель сохранена в '{model_file_100}'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0550af-5aad-46ab-c1f8-25fe6d935031",
        "id": "L9-_zOLmq1Sn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дообученная модель сохранена в 'updated_ocr_model_100.bin'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Тестирование дообученной модели на тестовых данных на 100 тыс. предложениях**"
      ],
      "metadata": {
        "id": "ZqJ1NXp-q1Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестирование дообученной модели\n",
        "new_corrector_100 = jamspell.TSpellCorrector()\n",
        "new_corrector_100.LoadLangModel(model_file_100)  # Загрузка дообученной модели"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8cde7a-94eb-4530-f02f-a45a58f30915",
        "id": "kEsB8-L-q1Sn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открытие файла тестовых данных\n",
        "# Файл с тестовыми текстами (текст с ошибками -> эталонный текст)\n",
        "test_file_path = \"test_100.txt\"\n",
        "results_file_path = \"test_results_100.txt\"  # Файл для записи результатов\n",
        "\n",
        "# Запись результатов тестирования\n",
        "with open(test_file_path,\n",
        "          \"r\",\n",
        "          encoding=\"utf-8\") as test_file,\n",
        "          open(results_file_path,\n",
        "              \"w\",\n",
        "              encoding=\"utf-8\") as results_file:\n",
        "    for line in test_file:\n",
        "        line = line.strip()  # Убираем лишние пробелы и переводы строк\n",
        "\n",
        "        if \" -> \" not in line:\n",
        "            print(f\"Ошибка в строке: {line}\")  # Выводим проблемную строку\n",
        "            continue  # Пропускаем строки, которые не соответствуют формату\n",
        "        # Разделяем OCR текст и эталонный текст\n",
        "        ocr_text, correct_text = line.split(\" -> \", 1)\n",
        "        # Исправление текста с помощью дообученной модели\n",
        "        corrected_text = new_corrector_100.FixFragment(ocr_text)\n",
        "\n",
        "        # Запись результатов в файл\n",
        "        results_file.write(f\"OCR текст:        {ocr_text}\\n\")\n",
        "        results_file.write(f\"Эталонный текст:  {correct_text}\\n\")\n",
        "        results_file.write(f\"Откоррект. текст: {corrected_text}\\n\")\n",
        "\n",
        "        # Пустая строка между блоками для удобства чтения\n",
        "        results_file.write(\"\\n\")\n",
        "print(f\"Результаты тестирования сохранены в '{results_file_path}'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9262fb-6295-436d-ef0d-dbc23b21af29",
        "id": "TtT7aay9q1Sn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты тестирования сохранены в 'test_results_100.txt'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод результатов дообученной модели по сравнению с эталонным текстом и текстом с ошибками."
      ],
      "metadata": {
        "id": "SFF0H4pHq1Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение первых строк из файла и вывод на экран\n",
        "file_res_path = \"test_results_100.txt\"  # Путь к файлу\n",
        "\n",
        "with open(file_res_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(24):  # Чтение и вывод первых строк\n",
        "        # Считываем строку и убираем лишние пробелы\n",
        "        line = file.readline().strip()\n",
        "        print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae157e18-0066-4e2c-f687-402e427824a6",
        "id": "xHJNLzsgq1So"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR текст:        Ее черные гла3а сматрели на нас насгороженно и даже немного сердито\n",
            "Эталонный текст:  Ее черные глаза смотрели на нас настороженно и даже немного сердито\n",
            "Откоррект. текст: Ее черные гла3а сматрели на нас настороженно и даже немного сердито\n",
            "\n",
            "OCR текст:        Я и сообразить-то ничего не уепел\n",
            "Эталонный текст:  Я и сообразить-то ничего не успел\n",
            "Откоррект. текст: Я и сообразить-то ничего не уепел\n",
            "\n",
            "OCR текст:        О 0боротнями никогда не цгадаешь… А 4его ты так цдивился\n",
            "Эталонный текст:  С оборотнями никогда не угадаешь… А чего ты так удивился\n",
            "Откоррект. текст: О 0боротнями никогда не угадаешь… А 4его ты так цдивился\n",
            "\n",
            "OCR текст:        –Лучше бы ты любйл, чем берёг\n",
            "Эталонный текст:  –Лучше бы ты любил, чем берег\n",
            "Откоррект. текст: –Лучше бы ты любил, чем берёг\n",
            "\n",
            "OCR текст:        –Как угодпо.– Завулон пож@л плёчами.– Повторяю, пока мы прёдлагаем свои чслуги\n",
            "Эталонный текст:  –Как угодно.– Завулон пожал плечами.– Повторяю, пока мы предлагаем свои услуги\n",
            "Откоррект. текст: –Как угодпо.– Завулон пож@л плёчами.– Повторяю, пока мы предлагаем свои услуги\n",
            "\n",
            "OCR текст:        Я вздохнул\n",
            "Эталонный текст:  Я вздохнул\n",
            "Откоррект. текст: Я вздохнул\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим другой текст, должен исправить ошибки\n",
        "print(new_corrector_100.FixFragment(\"Тексмт с ошбиками. Превет! Эжономисты ачень долго не котели абсуждать роль общества в экономике\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f096b38c-f316-4b46-bf6e-055f8c44816e",
        "id": "arocMfoJq1So"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст с ошбиками. Привет! Экономисты ачень долго не котели обсуждать роль общества в экономике\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Дообучение на 200 тыс. предложениях.**"
      ],
      "metadata": {
        "id": "tSkO9UmrsIvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация JamSpell и загрузка предобученной модели для 200 тыс.предложений\n",
        "corrector = jamspell.TSpellCorrector()\n",
        "corrector.LoadLangModel(\"ru_small.bin\")\n",
        "print(\"Предобученная модель 'ru_small.bin' успешно загружена!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d59ad2-6c21-43d7-d1e5-515762587f55",
        "id": "a4ANsllzpkOH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предобученная модель 'ru_small.bin' успешно загружена!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_text(dataset, output_file):\n",
        "    \"\"\"\n",
        "    Экспортирует Dataset в текстовый файл. Каждая строка - исправленный текст.\n",
        "    \"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        #for sample in dataset_total['train']:\n",
        "        for sample in dataset:\n",
        "            ocr_text = sample['source']        # Текст с OCR-ошибками\n",
        "            correct_text = sample['correction']  # Эталонный текст\n",
        "            # Пишем пару OCR -> исправление\n",
        "            f.write(f\"{ocr_text} -> {correct_text}\\n\")"
      ],
      "metadata": {
        "id": "MAxYezBNe-0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлекаем и сохраняем train/test в текстовые файлы на 200 тыс. предложений\n",
        "train_file = \"train.txt\"\n",
        "test_file = \"test.txt\"\n",
        "export_to_text(dataset_total[\"train\"], train_file)\n",
        "export_to_text(dataset_total[\"test\"], test_file)\n",
        "print(f\"Данные сохранены:\\n - Train: {train_file}\\n - Test: {test_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGcVCRwpfRhm",
        "outputId": "fb98219d-fe7b-4f56-cf97-2b35ea4e8e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные сохранены:\n",
            " - Train: train.txt\n",
            " - Test: test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение первых 5 строк из файла и вывод на экран\n",
        "with open(train_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(5):  # Чтение и вывод первых 5 строк\n",
        "        # Считываем строку и убираем лишние пробелы\n",
        "        line = file.readline().strip()\n",
        "        print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmDk5HEwdpnc",
        "outputId": "aba12780-ccc2-4d74-d2e8-06b1d572655d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "А вместе с людьми сп0койно и интересн0 -> А вместе с людьми спокойно и интересно\n",
            "И тольжо Триллиан не подняла свой пистолет -> И только Триллиан не подняла свой пистолет\n",
            "Внезапно грудь сгарика приподнялась -> Внезапно грудь старика приподнялась\n",
            "Коридор увел вглубь д0ма, в квартиру Зуевых -> Коридор увел вглубь дома, в квартиру Зуевых\n",
            "–Смотри -> –Смотри\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Дообучение JamSpell на OCR-ошибках (с использованием тренировочного файла)\n",
        "alphabet_file = \"alphabet.txt\"\n",
        "with open(alphabet_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    alphabet = \"абвгдежзийклмнопрстуфхцчшщъыьэюяё\"\n",
        "    f.write(\"\\n\".join(alphabet))"
      ],
      "metadata": {
        "id": "B9xuLu67YbFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дообучить модель JamSpell на этих данных. Сохранить обновленную модель."
      ],
      "metadata": {
        "id": "vpFkn4VWcJNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Дообучение модели (на OCR-ошибках)\n",
        "model_file = \"updated_ocr_model.bin\"\n",
        "corrector.TrainLangModel(train_file, alphabet_file, model_file)\n",
        "print(f\"Дообученная модель сохранена в '{model_file}'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9_wpfQeYbFS",
        "outputId": "f07896d2-2995-4bdd-a734-225e1785fa48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дообученная модель сохранена в 'updated_ocr_model.bin'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Тестирование дообученной модели на тестовых данных 200 тыс.предложений**"
      ],
      "metadata": {
        "id": "Z7BqWL7Rnno8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестирование дообученной модели\n",
        "new_corrector = jamspell.TSpellCorrector()\n",
        "new_corrector.LoadLangModel(model_file)  # Загрузка дообученной модели"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20acd16d-1cf2-4c0d-c872-98ef4887e962",
        "id": "T5Mbcy-7jq5n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открытие файла тестовых данных\n",
        "# Файл с тестовыми текстами (текст с ошибками -> эталонный текст)\n",
        "test_file_path = \"test.txt\"\n",
        "results_file_path = \"test_results.txt\"  # Файл для записи результатов\n",
        "\n",
        "# Запись результатов тестирования\n",
        "with open(test_file_path,\n",
        "          \"r\",\n",
        "          encoding=\"utf-8\") as test_file,\n",
        "          open(results_file_path,\n",
        "               \"w\",\n",
        "               encoding=\"utf-8\") as results_file:\n",
        "    for line in test_file:\n",
        "        line = line.strip()  # Убираем лишние пробелы и переводы строк\n",
        "\n",
        "        if \" -> \" not in line:\n",
        "            print(f\"Ошибка в строке: {line}\")  # Выводим проблемную строку\n",
        "            continue  # Пропускаем строки, которые не соответствуют формату\n",
        "        # Разделяем OCR текст и эталонный текст\n",
        "        ocr_text, correct_text = line.split(\" -> \", 1)\n",
        "        # Исправление текста с помощью дообученной модели\n",
        "        corrected_text = new_corrector.FixFragment(ocr_text)\n",
        "\n",
        "        # Запись результатов в файл\n",
        "        results_file.write(f\"OCR текст:        {ocr_text}\\n\")\n",
        "        results_file.write(f\"Эталонный текст:  {correct_text}\\n\")\n",
        "        results_file.write(f\"Откоррект. текст: {corrected_text}\\n\")\n",
        "        # Пустая строка между блоками для удобства чтения\n",
        "        results_file.write(\"\\n\")\n",
        "\n",
        "print(f\"Результаты тестирования сохранены в '{results_file_path}'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_gU-Wev0Uei",
        "outputId": "e3a0d0af-432b-4c34-911d-9000252c75ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка в строке: ->\n",
            "Результаты тестирования сохранены в 'test_results.txt'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод результатов дообученной модели по сравнению с эталонным текстом и текстом с ошибками."
      ],
      "metadata": {
        "id": "DPDoLZeucWhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение первых строк из файла и вывод на экран\n",
        "file_res_path = \"test_results.txt\"  # Путь к вашему файлу\n",
        "\n",
        "with open(file_res_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(24):  # Чтение и вывод первых строк\n",
        "        # Считываем строку и убираем лишние пробелы\n",
        "        line = file.readline().strip()\n",
        "        print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a6ea53-1c49-4a99-df65-517ef5f63f81",
        "id": "MBHmzfW0eT5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR текст:        3начит, там, где растут эти дёревья, вечпые лнхорадки…  –Вовсе нет\n",
            "Эталонный текст:  Значит, там, где растут эти деревья, вечные лихорадки…  –Вовсе нет\n",
            "Откоррект. текст: 3начит, там, где растут эти дёревья, вечные лнхорадки…  –Вовсе нет\n",
            "\n",
            "OCR текст:        –А когда это я ныл по пустякам\n",
            "Эталонный текст:  –А когда это я ныл по пустякам\n",
            "Откоррект. текст: –А когда это я был по пустякам\n",
            "\n",
            "OCR текст:        К моему и квашему несчастью, я не в силах освободить вас из злого плена\n",
            "Эталонный текст:  К моему и квашему несчастью, я не в силах освободить вас из злого плена\n",
            "Откоррект. текст: К моему и вашему несчастью, я не в силах освободить вас из злого плена\n",
            "\n",
            "OCR текст:        В домашней куртке, в мягких туфлях, то есгь сапого безмятёжного вида\n",
            "Эталонный текст:  В домашней куртке, в мягких туфлях, то есть самого безмятежного вида\n",
            "Откоррект. текст: В домашней куртке, в мягких туфлях, то есгь сапого безмятёжного вида\n",
            "\n",
            "OCR текст:        Жээ, сказал бы кто-ни6удь Масахиро Сибаге во врепена далекой иокогамекой юности, что ои будет питаться лежалым жйром давпо издохшей свиньй,– вырвало 6ы\n",
            "Эталонный текст:  Хээ, сказал бы кто-нибудь Масахиро Сибате во времена далекой иокогамской юности, что он будет питаться лежалым жиром давно издохшей свиньи,– вырвало бы\n",
            "Откоррект. текст: Жээ, сказал бы кто-ни6удь Масахиро Сибага во врепена далекой иокогамекой юности, что ои будет питаться лежал жаром давпо издохшей свинья,– вырвало 6ы\n",
            "\n",
            "OCR текст:        Впрочем, сейч@с мне было не до ра3мышлений\n",
            "Эталонный текст:  Впрочем, сейчас мне было не до размышлений\n",
            "Откоррект. текст: Впрочем, сейч@с мне было не до ра3мышления\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим другой текст, должен исправить ошибки\n",
        "print(new_corrector.FixFragment(\"Тексмт с ошбиками. Превет! Эжономисты ачень долго не котели абсуждать роль общества в экономике\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24s87gfXop5_",
        "outputId": "110026fa-df34-48b1-85fa-dad186755ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст с ошбиками. Привет! Эжономисты ачень долго не котели абсуждать роль общества в экономике\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**РЕЗУЛЬТАТ:**\n",
        "\n",
        "Визуально видно, что дообучение прошло не очень эффективно и исправляет не все ошибки. Возможно, что объем текста недотаточен или тип модели не позволяет повысить эффективность."
      ],
      "metadata": {
        "id": "fUye9AzdcpGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Анализ метрик после дообучения**"
      ],
      "metadata": {
        "id": "9BOw3rLw6sFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "После дообучения проанализируем метрики и сравним: метрики текста с ошибками и метрики откорректированного текста после дообучения."
      ],
      "metadata": {
        "id": "y_D4wKpE6z4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Метрики для дообучения текстов на 100 тыс. предложениях.**"
      ],
      "metadata": {
        "id": "S739WRrmtN2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация пустых списков\n",
        "ocr_texts_100 = []\n",
        "correct_texts_100 = []\n",
        "corrected_texts_100 = []\n",
        "\n",
        "# Чтение файла результатов\n",
        "with open(\"test_results_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        # Ищем строку с OCR текстом\n",
        "        if lines[i].startswith(\"OCR текст:\"):\n",
        "            # Извлекаем OCR текст (удаляем префикс и лишние пробелы)\n",
        "            ocr = lines[i].split(\":\", 1)[1].strip()\n",
        "            ocr_texts_100.append(ocr)\n",
        "\n",
        "            # Извлекаем эталонный текст (следующая строка)\n",
        "            correct = lines[i+1].split(\":\", 1)[1].strip()\n",
        "            correct_texts_100.append(correct)\n",
        "\n",
        "            # Извлекаем исправленный текст (через строку)\n",
        "            corrected = lines[i+2].split(\":\", 1)[1].strip()\n",
        "            corrected_texts_100.append(corrected)\n",
        "\n",
        "            # Пропускаем 4 строки (3 данные + 1 пустая)\n",
        "            i += 4\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "# Проверка результатов\n",
        "print(f\"Извлечено {len(ocr_texts_100)} записей:\")\n",
        "print(\"OCR тексты:         \", ocr_texts_100[:3], \"...\")\n",
        "print(\"Эталонные тексты:   \", correct_texts_100[:3], \"...\")\n",
        "print(\"Исправленные тексты:\", corrected_texts_100[:3], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0d07e0-bf29-45d3-c350-3da37f32da4d",
        "id": "GKTMs7obtKW3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Извлечено 25376 записей:\n",
            "OCR тексты:          ['Ее черные гла3а сматрели на нас насгороженно и даже немного сердито', 'Я и сообразить-то ничего не уепел', 'О 0боротнями никогда не цгадаешь… А 4его ты так цдивился'] ...\n",
            "Эталонные тексты:    ['Ее черные глаза смотрели на нас настороженно и даже немного сердито', 'Я и сообразить-то ничего не успел', 'С оборотнями никогда не угадаешь… А чего ты так удивился'] ...\n",
            "Исправленные тексты: ['Ее черные гла3а сматрели на нас настороженно и даже немного сердито', 'Я и сообразить-то ничего не уепел', 'О 0боротнями никогда не угадаешь… А 4его ты так цдивился'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для текста сгенерированных OCR-ошибок."
      ],
      "metadata": {
        "id": "57TaN3DHtKW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_ocr_100, cer_ocr_100 = metrics_wer_cer(correct_texts_100,\n",
        "                                           ocr_texts_100)\n",
        "print(f\"WER: {wer_ocr_100}\")\n",
        "print(f\"CER: {cer_ocr_100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96fe631-74ca-40da-95e5-3c77b647bc09",
        "id": "JdNJwXhPtKW4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.326\n",
            "CER: 0.051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для текста с автокоррекцией с дообученной моделью."
      ],
      "metadata": {
        "id": "nrHY_R15tKW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_corr_100, cer_corr_100 = metrics_wer_cer(correct_texts_100,\n",
        "                                             corrected_texts_100)\n",
        "print(f\"WER: {wer_corr_100}\")\n",
        "print(f\"CER: {cer_corr_100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53830e6b-83f5-4959-c25c-3f044f87b7c0",
        "id": "l1lafERwtKW5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.295\n",
            "CER: 0.048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Метрики для дообучения текстов на 200 тыс. предложениях.**"
      ],
      "metadata": {
        "id": "-hr-B5TTt3Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация пустых списков\n",
        "ocr_texts = []\n",
        "correct_texts = []\n",
        "corrected_texts = []\n",
        "\n",
        "# Чтение файла результатов\n",
        "with open(\"test_results.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        # Ищем строку с OCR текстом\n",
        "        if lines[i].startswith(\"OCR текст:\"):\n",
        "            # Извлекаем OCR текст (удаляем префикс и лишние пробелы)\n",
        "            ocr = lines[i].split(\":\", 1)[1].strip()\n",
        "            ocr_texts.append(ocr)\n",
        "\n",
        "            # Извлекаем эталонный текст (следующая строка)\n",
        "            correct = lines[i+1].split(\":\", 1)[1].strip()\n",
        "            correct_texts.append(correct)\n",
        "\n",
        "            # Извлекаем исправленный текст (через строку)\n",
        "            corrected = lines[i+2].split(\":\", 1)[1].strip()\n",
        "            corrected_texts.append(corrected)\n",
        "\n",
        "            # Пропускаем 4 строки (3 данные + 1 пустая)\n",
        "            i += 4\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "# Проверка результатов\n",
        "print(f\"Извлечено {len(ocr_texts)} записей:\")\n",
        "print(\"OCR тексты:         \", ocr_texts[:3], \"...\")\n",
        "print(\"Эталонные тексты:   \", correct_texts[:3], \"...\")\n",
        "print(\"Исправленные тексты:\", corrected_texts[:3], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6RfPzwvWn9v",
        "outputId": "e0413484-7379-45ea-c74d-35ca000695d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Извлечено 48808 записей:\n",
            "OCR тексты:          ['3начит, там, где растут эти дёревья, вечпые лнхорадки…  –Вовсе нет', '–А когда это я ныл по пустякам', 'К моему и квашему несчастью, я не в силах освободить вас из злого плена'] ...\n",
            "Эталонные тексты:    ['Значит, там, где растут эти деревья, вечные лихорадки…  –Вовсе нет', '–А когда это я ныл по пустякам', 'К моему и квашему несчастью, я не в силах освободить вас из злого плена'] ...\n",
            "Исправленные тексты: ['3начит, там, где растут эти дёревья, вечные лнхорадки…  –Вовсе нет', '–А когда это я был по пустякам', 'К моему и вашему несчастью, я не в силах освободить вас из злого плена'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для текста сгенерированных OCR-ошибок."
      ],
      "metadata": {
        "id": "rdKO10eD8eiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_ocr, cer_ocr = metrics_wer_cer(correct_texts, ocr_texts)\n",
        "print(f\"WER: {wer_ocr}\")\n",
        "print(f\"CER: {cer_ocr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b895011-3cae-4ef6-ce9c-3a317a658b41",
        "id": "Otd16saUsuhQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.333\n",
            "CER: 0.051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для текста с автокоррекцией с дообученной моделью."
      ],
      "metadata": {
        "id": "o-ug1CcF8wwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_corr, cer_corr = metrics_wer_cer(correct_texts, corrected_texts)\n",
        "print(f\"WER: {wer_corr}\")\n",
        "print(f\"CER: {cer_corr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_jk76VetKbc",
        "outputId": "b6324cac-8acb-431b-88a2-278828c7a974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.304\n",
            "CER: 0.049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ВЫВОД:**\n",
        "\n",
        "Загружены несколько текстов и был сгенерирован датасет с синтетическими OCR-ошибками размером **104549** предложений. Модель **JamSpell** была дообучена на этом датасете, выведены результаты для сравнения и вычислены метрики WER и CER.\n",
        "\n",
        "**До дообучения (текст с OCR-ошибками):**\n",
        "WER: 0.326 и CER: 0.051\n",
        "\n",
        "**После дообучения (тестовый текст):**\n",
        "WER: 0.295 и CER: 0.048\n",
        "\n",
        "Дообучение модели **JamSpell** дало плохие результаты, несмотря на то, что в предыдущей работе по исследованию автокорректоров она показала лучшие результаты. Даже визуально очевидно, что ошибки исправлены плохо.\n",
        "\n",
        "Возможные причины:\n",
        "- датасет не достаточного объема для лучшего обучения,\n",
        "- ошибки сгенерированы не корректно,\n",
        "- тип модели не позволяет более эффективно обучить модель.\n",
        "Необходимо попробовать дообучить другую модель на основе нейросети с переносом расчетов на ГПУ.\n",
        "\n",
        "Датасет увеличен до **244033** предложений, однако, улучшения метрик это не дало.\n",
        "\n",
        "**До дообучения (текст с OCR-ошибками):**\n",
        "WER: 0.333 и CER: 0.051\n",
        "\n",
        "**После дообучения (тестовый текст):**\n",
        "WER: 0.304 и CER: 0.049\n",
        "\n",
        "Предполагаю, что надо пропробовать заменить модель на более эффективную, например, модель RuM2M100-1.2B. Однако, сложность работы с этой моделью будет в том, что она требует переноса на ГПУ и большой ресурс видеопамяти."
      ],
      "metadata": {
        "id": "NZnSOdf7GArW"
      }
    }
  ]
}